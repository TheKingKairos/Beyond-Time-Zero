{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45505463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0b0b67d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# import data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_cleaned = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/MIMIC-ED/event_level_with_lac_wbc.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# count NaNs\u001b[39;00m\n\u001b[32m      5\u001b[39m nan_counts = df_cleaned.isna().sum().sum()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/septic6/sepsis/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/septic6/sepsis/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/septic6/sepsis/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/septic6/sepsis/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:331\u001b[39m, in \u001b[36mgetstate\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# import data\n",
    "df_cleaned = pd.read_csv(\"../data/MIMIC-ED/event_level_with_lac_wbc.csv\")\n",
    "\n",
    "# count NaNs\n",
    "nan_counts = df_cleaned.isna().sum().sum()\n",
    "print(\"Number of NaNs in the DataFrame:\", nan_counts)\n",
    "\n",
    "# analyze data types of each column\n",
    "print(df_cleaned.dtypes)\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7aff95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaNs and their counts:\n",
      "pain_stay             171131\n",
      "chiefcomplaint           101\n",
      "icd_title              15935\n",
      "hadm_id              5649620\n",
      "sepsis_onset_time    4537570\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# locate the nans\n",
    "nan_columns = df_cleaned.isna().sum()\n",
    "nan_columns = nan_columns[nan_columns > 0]\n",
    "print(\"Columns with NaNs and their counts:\")\n",
    "print(nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65155871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df_cleaned.drop(columns=nan_columns.index)\n",
    "print(df_cleaned.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a2c1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of septic patients: 2339\n",
      "Number of patients in small df: 4678\n"
     ]
    }
   ],
   "source": [
    "# group patients by \"stay_id\" and take 2000 random patients\n",
    "patient_ids = df_cleaned[\"stay_id\"].unique()\n",
    "# make sure there are 1000 septic and 1000 nonseptic patients\n",
    "#extract stay_ids with sepsis_dx_any == 1\n",
    "septic_patient_ids = df_cleaned[df_cleaned[\"sepsis_dx_any\"] == 1][\"stay_id\"].unique()\n",
    "# count of septic patients\n",
    "count_septic = len(septic_patient_ids)\n",
    "print(\"Number of septic patients:\", count_septic)\n",
    "nonseptic_patient_ids = df_cleaned[df_cleaned[\"sepsis_dx_any\"] == 0][\"stay_id\"].unique()\n",
    "# take 2 times septic number of random patients from the nonseptic patients\n",
    "random_nonseptic_patient_ids = np.random.choice(nonseptic_patient_ids, size=count_septic, replace=False)\n",
    "random_patient_ids = np.concatenate([septic_patient_ids, random_nonseptic_patient_ids])\n",
    "#shuffle the ids and filter df to only include these patients\n",
    "np.random.shuffle(random_patient_ids)\n",
    "df_small = df_cleaned[df_cleaned[\"stay_id\"].isin(random_patient_ids)]\n",
    "print(\"Number of patients in small df:\", df_small[\"stay_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9549cf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sepsis cases in small df: 46702\n"
     ]
    }
   ],
   "source": [
    "# drop all other labels\n",
    "df_small_new = df_small.drop(columns=[\"sepsis_dx_any\", \"sepsis_dx\", \"sirs_count\", \"sirs_ge2\", \"is_sepsis_onset\"])\n",
    "count_sepsis = df_small_new[\"is_sepsis\"].sum()\n",
    "print(\"Number of sepsis cases in small df:\", count_sepsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa74d848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['stay_id', 'charttime', 'temperature', 'heartrate', 'resprate', 'o2sat',\n",
      "       'sbp', 'dbp', 'pain', 'rhythm_flag', 'med_rn', 'gsn_rn', 'gsn',\n",
      "       'is_antibiotic', 'ndc', 'etc_rn', 'etccode', 'hadm_id_x', 'intime',\n",
      "       'race', 'is_white', 'is_black', 'is_asian', 'is_hispanic',\n",
      "       'is_other_race', 'gender_F', 'gender_M', 'arrival_transport_AMBULANCE',\n",
      "       'arrival_transport_HELICOPTER', 'arrival_transport_OTHER',\n",
      "       'arrival_transport_UNKNOWN', 'arrival_transport_WALK IN', 'lactate',\n",
      "       'wbc', 'is_sepsis'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_small_new = df_small_new.drop(columns=[\"subject_id\", \"outtime\", \"disposition\", 'temperature_stay', 'heartrate_stay', 'resprate_stay','o2sat_stay', 'sbp_stay', 'dbp_stay', 'acuity'])\n",
    "print(df_small_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b255dbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stay_id                         0\n",
      "charttime                       0\n",
      "temperature                     0\n",
      "heartrate                       0\n",
      "resprate                        0\n",
      "o2sat                           0\n",
      "sbp                             0\n",
      "dbp                             0\n",
      "pain                            0\n",
      "rhythm_flag                     0\n",
      "med_rn                          0\n",
      "gsn_rn                          0\n",
      "gsn                             0\n",
      "is_antibiotic                   0\n",
      "ndc                             0\n",
      "etc_rn                          0\n",
      "etccode                         0\n",
      "hadm_id_x                       0\n",
      "intime                          0\n",
      "race                            0\n",
      "is_white                        0\n",
      "is_black                        0\n",
      "is_asian                        0\n",
      "is_hispanic                     0\n",
      "is_other_race                   0\n",
      "gender_F                        0\n",
      "gender_M                        0\n",
      "arrival_transport_AMBULANCE     0\n",
      "arrival_transport_HELICOPTER    0\n",
      "arrival_transport_OTHER         0\n",
      "arrival_transport_UNKNOWN       0\n",
      "arrival_transport_WALK IN       0\n",
      "lactate                         0\n",
      "wbc                             0\n",
      "is_sepsis                       0\n",
      "dtype: int64\n",
      "Index(['stay_id', 'temperature', 'heartrate', 'resprate', 'o2sat', 'sbp',\n",
      "       'dbp', 'pain', 'rhythm_flag', 'med_rn', 'gsn_rn', 'gsn',\n",
      "       'is_antibiotic', 'ndc', 'etc_rn', 'etccode', 'hadm_id_x', 'race',\n",
      "       'is_white', 'is_black', 'is_asian', 'is_hispanic', 'is_other_race',\n",
      "       'gender_F', 'gender_M', 'arrival_transport_AMBULANCE',\n",
      "       'arrival_transport_HELICOPTER', 'arrival_transport_OTHER',\n",
      "       'arrival_transport_UNKNOWN', 'arrival_transport_WALK IN', 'lactate',\n",
      "       'wbc', 'is_sepsis', 'time_since_adm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# drop columns with nan times\n",
    "print(df_small_new.isna().sum())\n",
    "df_small_new[\"time_since_adm\"] = (pd.to_datetime(df_small_new[\"charttime\"]) - pd.to_datetime(df_small_new[\"intime\"])).dt.total_seconds() / 3600.0\n",
    "df_small_new = df_small_new.drop(columns = [\"intime\", \"charttime\"])\n",
    "print(df_small_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92896330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common gsn values: [16599.0, 43952.0, 4490.0, 66419.0, 61716.0]\n"
     ]
    }
   ],
   "source": [
    "# get most common gsns for septic patients\n",
    "most_common_gsns = df_small_new['gsn'].value_counts().nlargest(5).index.tolist()\n",
    "print(\"Most common gsn values:\", most_common_gsns)\n",
    "\n",
    "# one hot encode gsn\n",
    "for gsn in most_common_gsns:\n",
    "    df_small_new[f'gsn_{gsn}'] = (df_small_new['gsn'] == gsn).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42354d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stay_id', 'temperature', 'heartrate', 'resprate', 'o2sat', 'sbp',\n",
       "       'dbp', 'pain', 'rhythm_flag', 'hadm_id_x', 'is_white', 'is_black',\n",
       "       'is_asian', 'is_hispanic', 'is_other_race', 'gender_F', 'gender_M',\n",
       "       'arrival_transport_AMBULANCE', 'arrival_transport_HELICOPTER',\n",
       "       'arrival_transport_OTHER', 'arrival_transport_UNKNOWN',\n",
       "       'arrival_transport_WALK IN', 'lactate', 'wbc', 'is_sepsis',\n",
       "       'time_since_adm', 'gsn_16599.0', 'gsn_43952.0', 'gsn_4490.0',\n",
       "       'gsn_66419.0', 'gsn_61716.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small_new = df_small_new.drop(columns=['race', 'gsn', 'gsn_rn', 'med_rn', 'is_antibiotic', 'ndc', 'etc_rn', 'etccode'])\n",
    "df_small_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dd3e28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stay_id                           int64\n",
      "temperature                     float64\n",
      "heartrate                       float64\n",
      "resprate                        float64\n",
      "o2sat                           float64\n",
      "sbp                             float64\n",
      "dbp                             float64\n",
      "pain                            float64\n",
      "rhythm_flag                       int64\n",
      "hadm_id_x                       float64\n",
      "is_white                          int64\n",
      "is_black                          int64\n",
      "is_asian                          int64\n",
      "is_hispanic                       int64\n",
      "is_other_race                     int64\n",
      "gender_F                          int64\n",
      "gender_M                          int64\n",
      "arrival_transport_AMBULANCE       int64\n",
      "arrival_transport_HELICOPTER      int64\n",
      "arrival_transport_OTHER           int64\n",
      "arrival_transport_UNKNOWN         int64\n",
      "arrival_transport_WALK IN         int64\n",
      "lactate                         float64\n",
      "wbc                             float64\n",
      "is_sepsis                         int64\n",
      "time_since_adm                  float64\n",
      "gsn_16599.0                       int64\n",
      "gsn_43952.0                       int64\n",
      "gsn_4490.0                        int64\n",
      "gsn_66419.0                       int64\n",
      "gsn_61716.0                       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# change all columns to numeric\n",
    "df_small_new_num = df_small_new.copy()\n",
    "for col in df_small_new_num.columns:\n",
    "    df_small_new_num[col] = pd.to_numeric(df_small_new_num[col], errors='coerce')\n",
    "\n",
    "# change all booleans to int\n",
    "bool_cols = df_small_new_num.select_dtypes(include=['bool']).columns\n",
    "df_small_new_num[bool_cols] = df_small_new_num[bool_cols].astype(int)\n",
    "print(df_small_new_num.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b1715fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stay_id', 'temperature', 'heartrate', 'resprate', 'o2sat', 'sbp',\n",
       "       'dbp', 'pain', 'rhythm_flag', 'hadm_id_x', 'is_white', 'is_black',\n",
       "       'is_asian', 'is_hispanic', 'is_other_race', 'gender_F', 'gender_M',\n",
       "       'arrival_transport_AMBULANCE', 'arrival_transport_HELICOPTER',\n",
       "       'arrival_transport_OTHER', 'arrival_transport_UNKNOWN',\n",
       "       'arrival_transport_WALK IN', 'lactate', 'wbc', 'time_since_adm',\n",
       "       'gsn_16599.0', 'gsn_43952.0', 'gsn_4490.0', 'gsn_66419.0',\n",
       "       'gsn_61716.0', 'is_sepsis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reorder columns to have is_sepsis at the end\n",
    "cols = list(df_small_new_num.columns)\n",
    "cols.remove('is_sepsis')\n",
    "cols.append('is_sepsis')\n",
    "df_small_new_num = df_small_new_num[cols]\n",
    "df_small_new_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ebd3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that could cause data leakage\n",
    "df_small_new_num = df_small_new_num.drop(columns=['hadm_id_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dffac26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stay_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>resprate</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pain</th>\n",
       "      <th>rhythm_flag</th>\n",
       "      <th>is_white</th>\n",
       "      <th>...</th>\n",
       "      <th>arrival_transport_WALK IN</th>\n",
       "      <th>lactate</th>\n",
       "      <th>wbc</th>\n",
       "      <th>time_since_adm</th>\n",
       "      <th>gsn_16599.0</th>\n",
       "      <th>gsn_43952.0</th>\n",
       "      <th>gsn_4490.0</th>\n",
       "      <th>gsn_66419.0</th>\n",
       "      <th>gsn_61716.0</th>\n",
       "      <th>is_sepsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>37459204</td>\n",
       "      <td>98.1</td>\n",
       "      <td>79.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>37459204</td>\n",
       "      <td>102.9</td>\n",
       "      <td>92.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>37459204</td>\n",
       "      <td>102.9</td>\n",
       "      <td>92.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>37459204</td>\n",
       "      <td>104.2</td>\n",
       "      <td>83.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>37459204</td>\n",
       "      <td>104.2</td>\n",
       "      <td>83.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6136674</th>\n",
       "      <td>39316677</td>\n",
       "      <td>98.5</td>\n",
       "      <td>118.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>10.650000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6136675</th>\n",
       "      <td>39316677</td>\n",
       "      <td>98.5</td>\n",
       "      <td>118.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>11.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6136676</th>\n",
       "      <td>39316677</td>\n",
       "      <td>98.5</td>\n",
       "      <td>130.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>11.133333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6136677</th>\n",
       "      <td>39316677</td>\n",
       "      <td>98.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>11.516667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6136678</th>\n",
       "      <td>39316677</td>\n",
       "      <td>98.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96556 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          stay_id  temperature  heartrate  resprate  o2sat    sbp    dbp  \\\n",
       "626      37459204         98.1       79.0      18.0   98.0  126.0   72.0   \n",
       "627      37459204        102.9       92.0      18.0   94.0  123.0   53.0   \n",
       "628      37459204        102.9       92.0      18.0   94.0  123.0   53.0   \n",
       "629      37459204        104.2       83.0      22.0   93.0  111.0   48.0   \n",
       "630      37459204        104.2       83.0      22.0   93.0  111.0   48.0   \n",
       "...           ...          ...        ...       ...    ...    ...    ...   \n",
       "6136674  39316677         98.5      118.0      23.0   97.0  117.0   82.0   \n",
       "6136675  39316677         98.5      118.0      23.0   97.0  117.0   82.0   \n",
       "6136676  39316677         98.5      130.0      20.0   99.0  132.0  100.0   \n",
       "6136677  39316677         98.0      124.0      19.0  100.0  121.0   73.0   \n",
       "6136678  39316677         98.0      112.0      16.0   99.0  113.0   77.0   \n",
       "\n",
       "         pain  rhythm_flag  is_white  ...  arrival_transport_WALK IN  lactate  \\\n",
       "626       0.0            0         1  ...                          0      1.6   \n",
       "627       0.0            0         1  ...                          0      1.6   \n",
       "628       0.0            0         1  ...                          0      1.6   \n",
       "629       0.0            0         1  ...                          0      3.2   \n",
       "630       0.0            0         1  ...                          0      3.2   \n",
       "...       ...          ...       ...  ...                        ...      ...   \n",
       "6136674   0.0            0         0  ...                          1      1.8   \n",
       "6136675   0.0            0         0  ...                          1      1.8   \n",
       "6136676   0.0            0         0  ...                          1      1.8   \n",
       "6136677   0.0            0         0  ...                          1      1.8   \n",
       "6136678   0.0            0         0  ...                          1      1.8   \n",
       "\n",
       "          wbc  time_since_adm  gsn_16599.0  gsn_43952.0  gsn_4490.0  \\\n",
       "626       7.8        0.016667            1            0           0   \n",
       "627       7.8        0.083333            1            0           0   \n",
       "628       7.8        0.150000            0            0           0   \n",
       "629       7.8        0.450000            0            0           0   \n",
       "630      15.6        1.083333            0            0           0   \n",
       "...       ...             ...          ...          ...         ...   \n",
       "6136674   7.7       10.650000            0            0           0   \n",
       "6136675   7.7       11.033333            0            0           0   \n",
       "6136676   7.7       11.133333            0            0           0   \n",
       "6136677   7.7       11.516667            0            0           0   \n",
       "6136678   7.7       11.800000            0            0           0   \n",
       "\n",
       "         gsn_66419.0  gsn_61716.0  is_sepsis  \n",
       "626                0            0          0  \n",
       "627                0            0          1  \n",
       "628                0            0          1  \n",
       "629                0            0          1  \n",
       "630                0            0          1  \n",
       "...              ...          ...        ...  \n",
       "6136674            0            0          1  \n",
       "6136675            0            0          1  \n",
       "6136676            0            0          1  \n",
       "6136677            0            0          1  \n",
       "6136678            0            0          1  \n",
       "\n",
       "[96556 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small_new_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bad4f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small_new_num.to_csv(\"../data/MIMIC-ED/event_level_training_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275849e7",
   "metadata": {},
   "source": [
    "# Survival Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5576807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs in the DataFrame: 10374357\n",
      "subject_id                        int64\n",
      "stay_id                           int64\n",
      "charttime                        object\n",
      "temperature                     float64\n",
      "heartrate                       float64\n",
      "resprate                        float64\n",
      "o2sat                           float64\n",
      "sbp                             float64\n",
      "dbp                             float64\n",
      "pain                            float64\n",
      "rhythm_flag                       int64\n",
      "med_rn                          float64\n",
      "gsn_rn                          float64\n",
      "gsn                             float64\n",
      "is_antibiotic                     int64\n",
      "ndc                             float64\n",
      "etc_rn                          float64\n",
      "etccode                         float64\n",
      "hadm_id_x                       float64\n",
      "intime                           object\n",
      "outtime                          object\n",
      "race                             object\n",
      "disposition                      object\n",
      "temperature_stay                float64\n",
      "heartrate_stay                  float64\n",
      "resprate_stay                   float64\n",
      "o2sat_stay                      float64\n",
      "sbp_stay                        float64\n",
      "dbp_stay                        float64\n",
      "pain_stay                        object\n",
      "acuity                          float64\n",
      "chiefcomplaint                   object\n",
      "icd_title                        object\n",
      "is_white                          int64\n",
      "is_black                          int64\n",
      "is_asian                          int64\n",
      "is_hispanic                       int64\n",
      "is_other_race                     int64\n",
      "gender_F                           bool\n",
      "gender_M                           bool\n",
      "arrival_transport_AMBULANCE        bool\n",
      "arrival_transport_HELICOPTER       bool\n",
      "arrival_transport_OTHER            bool\n",
      "arrival_transport_UNKNOWN          bool\n",
      "arrival_transport_WALK IN          bool\n",
      "lactate                         float64\n",
      "hadm_id                         float64\n",
      "wbc                             float64\n",
      "sepsis_dx_any                     int64\n",
      "sepsis_dx                         int64\n",
      "sirs_count                        int64\n",
      "sirs_ge2                          int64\n",
      "sepsis_onset_time                object\n",
      "is_sepsis_onset                   int64\n",
      "is_sepsis                         int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>temperature</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>resprate</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pain</th>\n",
       "      <th>...</th>\n",
       "      <th>lactate</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>wbc</th>\n",
       "      <th>sepsis_dx_any</th>\n",
       "      <th>sepsis_dx</th>\n",
       "      <th>sirs_count</th>\n",
       "      <th>sirs_ge2</th>\n",
       "      <th>sepsis_onset_time</th>\n",
       "      <th>is_sepsis_onset</th>\n",
       "      <th>is_sepsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13238787</td>\n",
       "      <td>35341790</td>\n",
       "      <td>2110-01-11 01:49:00</td>\n",
       "      <td>98.4</td>\n",
       "      <td>77.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15350437</td>\n",
       "      <td>39042378</td>\n",
       "      <td>2110-01-11 03:45:00</td>\n",
       "      <td>97.1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13238787</td>\n",
       "      <td>35341790</td>\n",
       "      <td>2110-01-11 04:02:00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13238787</td>\n",
       "      <td>35341790</td>\n",
       "      <td>2110-01-11 05:21:00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13238787</td>\n",
       "      <td>35341790</td>\n",
       "      <td>2110-01-11 05:21:00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   stay_id            charttime  temperature  heartrate  \\\n",
       "0    13238787  35341790  2110-01-11 01:49:00         98.4       77.0   \n",
       "1    15350437  39042378  2110-01-11 03:45:00         97.1       71.0   \n",
       "2    13238787  35341790  2110-01-11 04:02:00         98.0       78.0   \n",
       "3    13238787  35341790  2110-01-11 05:21:00         98.0       78.0   \n",
       "4    13238787  35341790  2110-01-11 05:21:00         98.0       78.0   \n",
       "\n",
       "   resprate  o2sat    sbp    dbp  pain  ...  lactate  hadm_id  wbc  \\\n",
       "0      16.0  100.0  149.0  104.0   8.0  ...      1.6      NaN  7.8   \n",
       "1      16.0  100.0  117.0   79.0   0.0  ...      1.6      NaN  7.8   \n",
       "2      18.0   99.0  138.0   92.0   0.0  ...      1.6      NaN  7.8   \n",
       "3      18.0   99.0  138.0   92.0   0.0  ...      1.6      NaN  7.8   \n",
       "4      18.0   99.0  138.0   92.0   0.0  ...      1.6      NaN  7.8   \n",
       "\n",
       "   sepsis_dx_any  sepsis_dx  sirs_count  sirs_ge2  sepsis_onset_time  \\\n",
       "0              0          0           0         0                NaN   \n",
       "1              0          0           0         0                NaN   \n",
       "2              0          0           0         0                NaN   \n",
       "3              0          0           0         0                NaN   \n",
       "4              0          0           0         0                NaN   \n",
       "\n",
       "   is_sepsis_onset is_sepsis  \n",
       "0                0         0  \n",
       "1                0         0  \n",
       "2                0         0  \n",
       "3                0         0  \n",
       "4                0         0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# import data\n",
    "df_cleaned = pd.read_csv(\"../data/MIMIC-ED/event_level_with_lac_wbc.csv\")\n",
    "\n",
    "# count NaNs\n",
    "nan_counts = df_cleaned.isna().sum().sum()\n",
    "print(\"Number of NaNs in the DataFrame:\", nan_counts)\n",
    "\n",
    "# analyze data types of each column\n",
    "print(df_cleaned.dtypes)\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d296e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of septic patients: 2339\n",
      "Number of patients in small df: 4678\n"
     ]
    }
   ],
   "source": [
    "# group patients by \"stay_id\" and take 2000 random patients\n",
    "patient_ids = df_cleaned[\"stay_id\"].unique()\n",
    "# make sure there are 1000 septic and 1000 nonseptic patients\n",
    "#extract stay_ids with sepsis_dx_any == 1\n",
    "septic_patient_ids = df_cleaned[df_cleaned[\"sepsis_dx_any\"] == 1][\"stay_id\"].unique()\n",
    "# count of septic patients\n",
    "count_septic = len(septic_patient_ids)\n",
    "print(\"Number of septic patients:\", count_septic)\n",
    "nonseptic_patient_ids = df_cleaned[df_cleaned[\"sepsis_dx_any\"] == 0][\"stay_id\"].unique()\n",
    "# take 2 times septic number of random patients from the nonseptic patients\n",
    "random_nonseptic_patient_ids = np.random.choice(nonseptic_patient_ids, size=count_septic, replace=False)\n",
    "random_patient_ids = np.concatenate([septic_patient_ids, random_nonseptic_patient_ids])\n",
    "#shuffle the ids and filter df to only include these patients\n",
    "np.random.shuffle(random_patient_ids)\n",
    "df_small = df_cleaned[df_cleaned[\"stay_id\"].isin(random_patient_ids)]\n",
    "print(\"Number of patients in small df:\", df_small[\"stay_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c95e2b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_id                          0\n",
      "stay_id                             0\n",
      "charttime                           0\n",
      "temperature                         0\n",
      "heartrate                           0\n",
      "resprate                            0\n",
      "o2sat                               0\n",
      "sbp                                 0\n",
      "dbp                                 0\n",
      "pain                                0\n",
      "rhythm_flag                         0\n",
      "med_rn                              0\n",
      "gsn_rn                              0\n",
      "gsn                                 0\n",
      "is_antibiotic                       0\n",
      "ndc                                 0\n",
      "etc_rn                              0\n",
      "etccode                             0\n",
      "hadm_id_x                           0\n",
      "intime                              0\n",
      "outtime                             0\n",
      "race                                0\n",
      "disposition                         0\n",
      "temperature_stay                    0\n",
      "heartrate_stay                      0\n",
      "resprate_stay                       0\n",
      "o2sat_stay                          0\n",
      "sbp_stay                            0\n",
      "dbp_stay                            0\n",
      "pain_stay                        7761\n",
      "acuity                              0\n",
      "chiefcomplaint                      0\n",
      "icd_title                         111\n",
      "is_white                            0\n",
      "is_black                            0\n",
      "is_asian                            0\n",
      "is_hispanic                         0\n",
      "is_other_race                       0\n",
      "gender_F                            0\n",
      "gender_M                            0\n",
      "arrival_transport_AMBULANCE         0\n",
      "arrival_transport_HELICOPTER        0\n",
      "arrival_transport_OTHER             0\n",
      "arrival_transport_UNKNOWN           0\n",
      "arrival_transport_WALK IN           0\n",
      "lactate                             0\n",
      "hadm_id                         88268\n",
      "wbc                                 0\n",
      "sepsis_dx_any                       0\n",
      "sepsis_dx                           0\n",
      "sirs_count                          0\n",
      "sirs_ge2                            0\n",
      "sepsis_onset_time               35736\n",
      "is_sepsis_onset                     0\n",
      "is_sepsis                           0\n",
      "dtype: int64\n",
      "Index(['subject_id', 'stay_id', 'charttime', 'temperature', 'heartrate',\n",
      "       'resprate', 'o2sat', 'sbp', 'dbp', 'pain', 'rhythm_flag', 'med_rn',\n",
      "       'gsn_rn', 'gsn', 'is_antibiotic', 'ndc', 'etc_rn', 'etccode',\n",
      "       'hadm_id_x', 'intime', 'outtime', 'race', 'disposition',\n",
      "       'temperature_stay', 'heartrate_stay', 'resprate_stay', 'o2sat_stay',\n",
      "       'sbp_stay', 'dbp_stay', 'pain_stay', 'acuity', 'chiefcomplaint',\n",
      "       'icd_title', 'is_white', 'is_black', 'is_asian', 'is_hispanic',\n",
      "       'is_other_race', 'gender_F', 'gender_M', 'arrival_transport_AMBULANCE',\n",
      "       'arrival_transport_HELICOPTER', 'arrival_transport_OTHER',\n",
      "       'arrival_transport_UNKNOWN', 'arrival_transport_WALK IN', 'lactate',\n",
      "       'hadm_id', 'wbc', 'sepsis_dx_any', 'sepsis_dx', 'sirs_count',\n",
      "       'sirs_ge2', 'sepsis_onset_time', 'is_sepsis_onset', 'is_sepsis',\n",
      "       'time_since_adm'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2850058/2321630792.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_small[\"time_since_adm\"] = (pd.to_datetime(df_small[\"charttime\"]) - pd.to_datetime(df_small[\"intime\"])).dt.total_seconds() / 3600.0\n"
     ]
    }
   ],
   "source": [
    "print(df_small.isna().sum())\n",
    "df_small[\"time_since_adm\"] = (pd.to_datetime(df_small[\"charttime\"]) - pd.to_datetime(df_small[\"intime\"])).dt.total_seconds() / 3600.0\n",
    "print(df_small.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7eb27ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_id                          0\n",
       "stay_id                             0\n",
       "charttime                           0\n",
       "temperature                         0\n",
       "heartrate                           0\n",
       "resprate                            0\n",
       "o2sat                               0\n",
       "sbp                                 0\n",
       "dbp                                 0\n",
       "pain                                0\n",
       "rhythm_flag                         0\n",
       "med_rn                              0\n",
       "gsn_rn                              0\n",
       "gsn                                 0\n",
       "is_antibiotic                       0\n",
       "ndc                                 0\n",
       "etc_rn                              0\n",
       "etccode                             0\n",
       "hadm_id_x                           0\n",
       "intime                              0\n",
       "outtime                             0\n",
       "race                                0\n",
       "disposition                         0\n",
       "temperature_stay                    0\n",
       "heartrate_stay                      0\n",
       "resprate_stay                       0\n",
       "o2sat_stay                          0\n",
       "sbp_stay                            0\n",
       "dbp_stay                            0\n",
       "pain_stay                        7761\n",
       "acuity                              0\n",
       "chiefcomplaint                      0\n",
       "icd_title                         111\n",
       "is_white                            0\n",
       "is_black                            0\n",
       "is_asian                            0\n",
       "is_hispanic                         0\n",
       "is_other_race                       0\n",
       "gender_F                            0\n",
       "gender_M                            0\n",
       "arrival_transport_AMBULANCE         0\n",
       "arrival_transport_HELICOPTER        0\n",
       "arrival_transport_OTHER             0\n",
       "arrival_transport_UNKNOWN           0\n",
       "arrival_transport_WALK IN           0\n",
       "lactate                             0\n",
       "hadm_id                         88268\n",
       "wbc                                 0\n",
       "sepsis_dx_any                       0\n",
       "sepsis_dx                           0\n",
       "sirs_count                          0\n",
       "sirs_ge2                            0\n",
       "sepsis_onset_time               35736\n",
       "is_sepsis_onset                     0\n",
       "is_sepsis                           0\n",
       "time_since_adm                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cb3ebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2850058/3090882925.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[c] = _to_dt(df[c])\n",
      "/tmp/ipykernel_2850058/3090882925.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[c] = _to_dt(df[c])\n",
      "/tmp/ipykernel_2850058/3090882925.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[c] = _to_dt(df[c])\n",
      "/tmp/ipykernel_2850058/3090882925.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[c] = _to_dt(df[c])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is in drop set? False\n",
      "[OK] Built static Cox dataset: n=4016 (dropped_no_candidate=662, dropped_nonpos_duration=0)\n",
      "✅ Wrote ../data/MIMIC-ED/cox_static_random_train.csv (cols: 39, rows: 4016)\n",
      "is in drop set? False\n",
      "[OK] Time-varying dataset: rows=23296 | used_epsilon=68 | skipped_short=0\n",
      "✅ Wrote ../data/MIMIC-ED/cox_timevarying_train.csv (cols: 41, rows: 23296)\n",
      "is in drop set? False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2850058/3090882925.py:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[c] = _to_dt(df[c])\n",
      "/tmp/ipykernel_2850058/3090882925.py:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[c] = _to_dt(df[c])\n",
      "/tmp/ipykernel_2850058/3090882925.py:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[c] = _to_dt(df[c])\n",
      "/tmp/ipykernel_2850058/3090882925.py:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[c] = _to_dt(df[c])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Built survival-stacked (landmark) Cox dataset: n=49199 | dropped_nonpos=0 | no_candidates=662\n",
      "✅ Wrote ../data/MIMIC-ED/cox_static_landmark_stacked_train.csv (cols: 40, rows: 49199)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "# ----------------------------\n",
    "# Config (adjust paths as needed)\n",
    "# ----------------------------\n",
    "OUTPUT_PATH_STATIC = \"../data/MIMIC-ED/cox_static_random_train.csv\"\n",
    "OUTPUT_PATH_TVC    = \"../data/MIMIC-ED/cox_timevarying_train.csv\"\n",
    "OUTPUT_PATH_STATIC_STACKED = \"../data/MIMIC-ED/cox_static_landmark_stacked_train.csv\"\n",
    "RNG_SEED = 42\n",
    "\n",
    "# New schema\n",
    "ID_COLS   = [\"subject_id\", \"hadm_id\", 'stay_id', 'hadm_id_x']\n",
    "TIME_COLS = [\"charttime\", \"intime\", \"outtime\", \"sepsis_onset_time\"]\n",
    "\n",
    "# Labels / leak-prone columns to exclude from covariates\n",
    "LABEL_COLS = [\n",
    "    \"sepsis_dx_any\", \"sepsis_dx\",\n",
    "    \"sirs_count\", \"sirs_ge2\",\n",
    "    \"is_sepsis_onset\", \"is_sepsis\",\n",
    "    # Keep both event indicators & dx out of covariates\n",
    "]\n",
    "\n",
    "# Survival target columns\n",
    "DURATION_COL = \"duration\"  # hours\n",
    "EVENT_COL    = \"event\"     # 1 if event observed, else 0\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def _to_dt(s):\n",
    "    \"\"\"Parse to pandas datetime with coercion.\"\"\"\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "def hours_between(a, b):\n",
    "    \"\"\"Return positive hours (b - a) or NaN if any is NaT.\"\"\"\n",
    "    if pd.isna(a) or pd.isna(b):\n",
    "        return np.nan\n",
    "    return max(0.0, (b - a).total_seconds() / 3600.0)\n",
    "\n",
    "def _feature_columns(df: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"Numeric covariates only, excluding IDs/time/labels.\"\"\"\n",
    "    drop = set([c for c in ID_COLS if c in df.columns] +\n",
    "               [c for c in TIME_COLS if c in df.columns] +\n",
    "               [c for c in LABEL_COLS if c in df.columns])\n",
    "    print(\"is in drop set?\", \"time_since_adm\" in drop)\n",
    "    num_cols = df.select_dtypes(include=[np.number, \"bool\"]).columns.tolist()\n",
    "    return [c for c in num_cols if c not in drop]\n",
    "\n",
    "# def _stay_event_info(g: pd.DataFrame):\n",
    "#     \"\"\"\n",
    "#     Return (event_flag:int, event_time:Timestamp|NaT, censor_time:Timestamp|NaT).\n",
    "#       - event_flag = int(g['is_sepsis'].max() >= 1)\n",
    "#       - event_time = sepsis_onset_time if event_flag==1 else NaT\n",
    "#       - censor_time = outtime if censored (and available) else last observed charttime\n",
    "#     \"\"\"\n",
    "#     # Prefer a stable, stay-level interpretation\n",
    "#     is_event = int((g.get(\"is_sepsis\", pd.Series([0])).astype(int).max()) >= 1)\n",
    "\n",
    "#     # Choose a representative row for stay-level timestamps if repeated\n",
    "#     # Use first non-null across the group\n",
    "#     ev_times = _to_dt(g.get(\"sepsis_onset_time\"))\n",
    "#     event_time = ev_times.dropna().min() if is_event == 1 else pd.NaT\n",
    "\n",
    "#     out_times = _to_dt(g.get(\"outtime\"))\n",
    "#     out_time = out_times.dropna().min() if len(out_times.dropna()) else pd.NaT\n",
    "\n",
    "#     last_obs = _to_dt(g[\"charttime\"]).max()\n",
    "\n",
    "#     if is_event == 1:\n",
    "#         censor_time = pd.NaT  # not used for event stays\n",
    "#     else:\n",
    "#         censor_time = out_time if pd.notna(out_time) else last_obs\n",
    "\n",
    "#     return is_event, event_time, censor_time\n",
    "def _stay_event_info(g: pd.DataFrame) -> Tuple[int, Optional[pd.Timestamp], Optional[pd.Timestamp]]:\n",
    "    \"\"\"\n",
    "    Return (event_flag, event_time, censor_time) where event_time/censor_time\n",
    "    are either a pandas Timestamp or None.\n",
    "    \"\"\"\n",
    "    is_event = int((g.get(\"is_sepsis\", pd.Series([0])).astype(int).max()) >= 1)\n",
    "\n",
    "    ev_times = _to_dt(g.get(\"sepsis_onset_time\"))\n",
    "    event_time = ev_times.dropna().min() if is_event == 1 else None\n",
    "    if pd.isna(event_time):\n",
    "        event_time = None\n",
    "\n",
    "    out_times = _to_dt(g.get(\"outtime\"))\n",
    "    out_time = out_times.dropna().min() if len(out_times.dropna()) else None\n",
    "\n",
    "    last_obs = _to_dt(g[\"charttime\"]).max()\n",
    "    if pd.isna(last_obs):\n",
    "        last_obs = None\n",
    "\n",
    "    if is_event == 1:\n",
    "        censor_time = None\n",
    "    else:\n",
    "        censor_time = out_time if out_time is not None else last_obs\n",
    "\n",
    "    return is_event, event_time, censor_time\n",
    "\n",
    "\n",
    "# def _choose_random_baseline(g: pd.DataFrame, terminal_time: pd.Timestamp | pd.NaT, rng: np.random.Generator):\n",
    "#     \"\"\"\n",
    "#     For event stays: choose a random row with charttime < event_time.\n",
    "#     For censored stays: choose a random row with charttime < censor_time (to avoid zero duration).\n",
    "#     Returns the chosen row (Series) or None if not possible.\n",
    "#     \"\"\"\n",
    "#     ct = _to_dt(g[\"charttime\"])\n",
    "#     if pd.notna(terminal_time):\n",
    "#         candidates = g.loc[ct < terminal_time]\n",
    "#     else:\n",
    "#         # If terminal_time is NaT (shouldn't happen for censored), fallback to any row\n",
    "#         candidates = g\n",
    "\n",
    "#     if candidates.empty:\n",
    "#         return None\n",
    "#     sel = candidates.iloc[rng.integers(0, len(candidates))]\n",
    "#     return sel\n",
    "\n",
    "def _choose_random_baseline(g: pd.DataFrame, terminal_time: Optional[pd.Timestamp], rng: np.random.Generator):\n",
    "    \"\"\"\n",
    "    For event stays: choose a random row with charttime < event_time.\n",
    "    For censored stays: choose a random row with charttime < censor_time.\n",
    "    \"\"\"\n",
    "    ct = _to_dt(g[\"charttime\"])\n",
    "    if terminal_time is not None:\n",
    "        candidates = g.loc[ct < terminal_time]\n",
    "    else:\n",
    "        # If terminal_time is missing, there is nothing to measure duration to.\n",
    "        return None\n",
    "\n",
    "    if candidates.empty:\n",
    "        return None\n",
    "    sel = candidates.iloc[rng.integers(0, len(candidates))]\n",
    "    return sel\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Static Cox (one random row per stay)\n",
    "# ----------------------------\n",
    "def make_static_random_snapshot(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    id_col: str = \"stay_id\",\n",
    "    duration_col: str = DURATION_COL,\n",
    "    event_col: str = EVENT_COL,\n",
    "    seed: int = RNG_SEED,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Leakage-safe CoxPH table using new schema:\n",
    "      - Event stays: one random pre-event snapshot (charttime < sepsis_onset_time)\n",
    "      - Censored stays: one random snapshot strictly before censor_time (outtime if present, else last charttime)\n",
    "      - duration = hours from snapshot to event or censoring\n",
    "      - event = 1 if event observed, else 0\n",
    "    \"\"\"\n",
    "    assert id_col in df.columns, f\"Missing id column: {id_col}\"\n",
    "\n",
    "    # Ensure datetimes & sort\n",
    "    for c in [\"charttime\", \"intime\", \"outtime\", \"sepsis_onset_time\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = _to_dt(df[c])\n",
    "    df = df.dropna(subset=[\"charttime\"])\n",
    "    df = df.sort_values([id_col, \"charttime\"], kind=\"mergesort\")\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    feats = _feature_columns(df)\n",
    "\n",
    "    rows = []\n",
    "    dropped_no_candidate = 0\n",
    "    dropped_nonpos_duration = 0\n",
    "\n",
    "    for sid, g in df.groupby(id_col, sort=False):\n",
    "        g = g.reset_index(drop=True)\n",
    "        event_flag, event_time, censor_time = _stay_event_info(g)\n",
    "\n",
    "        terminal_time = event_time if event_flag == 1 else censor_time\n",
    "        if pd.isna(terminal_time):\n",
    "            # No valid terminal time and/or no observations\n",
    "            dropped_no_candidate += 1\n",
    "            continue\n",
    "\n",
    "        sel = _choose_random_baseline(g, terminal_time, rng)\n",
    "        if sel is None:\n",
    "            dropped_no_candidate += 1\n",
    "            continue\n",
    "\n",
    "        t0 = sel[\"charttime\"]\n",
    "        dur = hours_between(t0, terminal_time)\n",
    "        if not np.isfinite(dur) or dur <= 0:\n",
    "            dropped_nonpos_duration += 1\n",
    "            continue\n",
    "\n",
    "        row = {duration_col: float(dur), event_col: int(event_flag)}\n",
    "        for c in feats:\n",
    "            row[c] = sel[c]\n",
    "        rows.append(row)\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "\n",
    "    if not out.empty:\n",
    "        covs = [c for c in out.columns if c not in [duration_col, event_col]]\n",
    "        out = out[[duration_col, event_col] + covs]\n",
    "        out[duration_col] = out[duration_col].astype(float)\n",
    "        out[event_col] = out[event_col].astype(int)\n",
    "\n",
    "        if not set(out[event_col].unique()).issubset({0, 1}):\n",
    "            raise ValueError(\"event must be binary (0/1).\")\n",
    "\n",
    "    print(f\"[OK] Built static Cox dataset: n={len(out)} \"\n",
    "          f\"(dropped_no_candidate={dropped_no_candidate}, dropped_nonpos_duration={dropped_nonpos_duration})\")\n",
    "    return out\n",
    "\n",
    "# ----------------------------\n",
    "# Survival-stacked (landmark) Cox\n",
    "# ----------------------------\n",
    "def make_static_landmark_stack(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    id_col: str = \"stay_id\",\n",
    "    duration_col: str = DURATION_COL,\n",
    "    event_col: str = EVENT_COL,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each stay, create one row for EVERY landmark row (leakage-safe):\n",
    "      - Event stays: all rows with charttime < sepsis_onset_time\n",
    "      - Censored stays: all rows with charttime < censor_time (outtime else last charttime)\n",
    "      - duration = hours from landmark charttime to terminal time\n",
    "      - event = 1 if event observed, else 0\n",
    "    \"\"\"\n",
    "    assert id_col in df.columns, f\"Missing id column: {id_col}\"\n",
    "\n",
    "    # Ensure datetimes & sort\n",
    "    for c in [\"charttime\", \"intime\", \"outtime\", \"sepsis_onset_time\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = _to_dt(df[c])\n",
    "    df = df.dropna(subset=[\"charttime\"])\n",
    "    df = df.sort_values([id_col, \"charttime\"], kind=\"mergesort\")\n",
    "\n",
    "    feats = _feature_columns(df)\n",
    "\n",
    "    rows = []\n",
    "    n_dropped_nonpos = 0\n",
    "    n_no_candidates = 0\n",
    "\n",
    "    for sid, g in df.groupby(id_col, sort=False):\n",
    "        g = g.reset_index(drop=True)\n",
    "        event_flag, event_time, censor_time = _stay_event_info(g)\n",
    "        terminal_time = event_time if event_flag == 1 else censor_time\n",
    "\n",
    "        if pd.isna(terminal_time):\n",
    "            n_no_candidates += 1\n",
    "            continue\n",
    "\n",
    "        ct = g[\"charttime\"]\n",
    "        candidates = g.loc[ct < terminal_time]\n",
    "\n",
    "        if candidates.empty:\n",
    "            n_no_candidates += 1\n",
    "            continue\n",
    "\n",
    "        for _, sel in candidates.iterrows():\n",
    "            dur = hours_between(sel[\"charttime\"], terminal_time)\n",
    "            if not np.isfinite(dur) or dur <= 0:\n",
    "                n_dropped_nonpos += 1\n",
    "                continue\n",
    "\n",
    "            row = {duration_col: float(dur), event_col: int(event_flag)}\n",
    "            row[id_col] = sid\n",
    "            for c in feats:\n",
    "                row[c] = sel[c]\n",
    "            rows.append(row)\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "\n",
    "    if not out.empty:\n",
    "        covs = [c for c in out.columns if c not in [id_col, duration_col, event_col]]  # ✅ include id_col here\n",
    "        out = out[[id_col, duration_col, event_col] + covs]                            # ✅ put id first\n",
    "        out[duration_col] = out[duration_col].astype(float)\n",
    "        out[event_col] = out[event_col].astype(int)\n",
    "\n",
    "        if not set(out[event_col].unique()).issubset({0, 1}):\n",
    "            raise ValueError(\"event must be binary (0/1).\")\n",
    "\n",
    "    print(\"[OK] Built survival-stacked (landmark) Cox dataset: \"\n",
    "          f\"n={len(out)} | dropped_nonpos={n_dropped_nonpos} | no_candidates={n_no_candidates}\")\n",
    "    return out\n",
    "\n",
    "# ----------------------------\n",
    "# Time-varying (Andersen–Gill) long format\n",
    "# ----------------------------\n",
    "def make_time_varying_long(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    id_col: str = \"stay_id\",\n",
    "    start_col: str = \"start\",\n",
    "    stop_col: str = \"stop\",\n",
    "    event_col: str = \"event\",\n",
    "    epsilon_seconds: int = 1,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    lifelines.CoxTimeVaryingFitter-ready:\n",
    "      - Intervals are [start, stop) in HOURS since the first observed charttime in the stay.\n",
    "      - Covariates are taken from the row at 'start'.\n",
    "      - Event assignment uses right-closed rule: start <= event_time < stop.\n",
    "      - If event_time equals/after the last observed charttime, create a tiny terminal interval\n",
    "        [last_time, last_time + epsilon] with event=1. For censored stays, no terminal event row.\n",
    "    \"\"\"\n",
    "    required = [\"charttime\"]\n",
    "    for c in required:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Missing required column: {c}\")\n",
    "\n",
    "    df = df.copy()\n",
    "    for c in [\"charttime\", \"intime\", \"outtime\", \"sepsis_onset_time\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = _to_dt(df[c])\n",
    "    df = df.dropna(subset=[\"charttime\"])\n",
    "    df = df.sort_values([id_col, \"charttime\"], kind=\"mergesort\")\n",
    "\n",
    "    feats = _feature_columns(df)\n",
    "\n",
    "    rows = []\n",
    "    n_skipped_short = 0\n",
    "    n_eps_used = 0\n",
    "\n",
    "    for sid, g in df.groupby(id_col, sort=False):\n",
    "        g = g.drop_duplicates(subset=[\"charttime\"], keep=\"last\").reset_index(drop=True)\n",
    "        if len(g) == 0:\n",
    "            continue\n",
    "\n",
    "        event_flag, event_time, censor_time = _stay_event_info(g)\n",
    "        base_t = g.loc[0, \"charttime\"]\n",
    "        times = g[\"charttime\"].tolist()\n",
    "\n",
    "        # Build intervals between consecutive unique times\n",
    "        fired = False\n",
    "        for i in range(len(times) - 1):\n",
    "            t_start = times[i]\n",
    "            t_stop  = times[i + 1]\n",
    "\n",
    "            start_hr = hours_between(base_t, t_start)\n",
    "            stop_hr  = hours_between(base_t, t_stop)\n",
    "            if not np.isfinite(start_hr) or not np.isfinite(stop_hr) or stop_hr <= start_hr:\n",
    "                # Defensive guard\n",
    "                continue\n",
    "\n",
    "            ev = 0\n",
    "            if pd.notna(event_time) and (t_start <= event_time < t_stop):\n",
    "                ev = 1\n",
    "                fired = True\n",
    "\n",
    "            row = {\n",
    "                id_col: sid,\n",
    "                start_col: start_hr,\n",
    "                stop_col:  stop_hr,\n",
    "                event_col: ev,\n",
    "            }\n",
    "            for c in feats:\n",
    "                row[c] = g.loc[i, c]\n",
    "            rows.append(row)\n",
    "\n",
    "            if ev == 1:\n",
    "                break  # stop after first event\n",
    "\n",
    "        # No event inside intervals but event exists at/after last observation\n",
    "        if (not fired) and pd.notna(event_time):\n",
    "            last_time = times[-1]\n",
    "            if event_time >= last_time:\n",
    "                # Build terminal epsilon interval to carry the event\n",
    "                t_stop = last_time + pd.Timedelta(seconds=epsilon_seconds)\n",
    "                n_eps_used += 1\n",
    "\n",
    "                start_hr = hours_between(base_t, last_time)\n",
    "                stop_hr  = hours_between(base_t, t_stop)\n",
    "                if stop_hr > start_hr:\n",
    "                    row = {\n",
    "                        id_col: sid,\n",
    "                        start_col: start_hr,\n",
    "                        stop_col:  stop_hr,\n",
    "                        event_col: 1 if (last_time <= event_time < t_stop) else 0,\n",
    "                    }\n",
    "                    for c in feats:\n",
    "                        row[c] = g.iloc[-1][c]\n",
    "                    rows.append(row)\n",
    "                else:\n",
    "                    n_skipped_short += 1\n",
    "        # Censored stays: nothing extra; already wrote all non-event intervals\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "\n",
    "    if not out.empty:\n",
    "        bad = out[out[stop_col] <= out[start_col]]\n",
    "        if len(bad):\n",
    "            print(f\"[WARN] Dropping {len(bad)} non-positive intervals after construction.\")\n",
    "            out = out[out[stop_col] > out[start_col]]\n",
    "\n",
    "        if not set(out[event_col].unique()).issubset({0, 1}):\n",
    "            raise ValueError(\"event must be binary in time-varying data.\")\n",
    "\n",
    "    print(f\"[OK] Time-varying dataset: rows={len(out)} | used_epsilon={n_eps_used} | skipped_short={n_skipped_short}\")\n",
    "    return out\n",
    "\n",
    "# ----------------------------\n",
    "# Main\n",
    "# ----------------------------\n",
    "def main():\n",
    "    # Create output directory\n",
    "    Path(OUTPUT_PATH_STATIC).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = df_small\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    need = {\"stay_id\", \"charttime\", \"is_sepsis\"}\n",
    "    missing = need - set(df.columns)\n",
    "    if missing:\n",
    "        raise FileNotFoundError(f\"Input missing required columns: {missing}\")\n",
    "\n",
    "    # Build STATIC Cox table (leakage-safe)\n",
    "    cox_df = make_static_random_snapshot(df, id_col=\"stay_id\")\n",
    "    cox_df.to_csv(OUTPUT_PATH_STATIC, index=False)\n",
    "    print(f\"✅ Wrote {OUTPUT_PATH_STATIC} (cols: {cox_df.shape[1]}, rows: {cox_df.shape[0]})\")\n",
    "\n",
    "    # TIME-VARYING table for CoxTimeVaryingFitter\n",
    "    tv_df = make_time_varying_long(df, id_col=\"stay_id\")\n",
    "    tv_df.to_csv(OUTPUT_PATH_TVC, index=False)\n",
    "    print(f\"✅ Wrote {OUTPUT_PATH_TVC} (cols: {tv_df.shape[1]}, rows: {tv_df.shape[0]})\")\n",
    "\n",
    "    # SURVIVAL-STACKED (landmark) Cox table\n",
    "    cox_stack = make_static_landmark_stack(df, id_col=\"stay_id\")\n",
    "    cox_stack.to_csv(OUTPUT_PATH_STATIC_STACKED, index=False)\n",
    "    print(f\"✅ Wrote {OUTPUT_PATH_STATIC_STACKED} (cols: {cox_stack.shape[1]}, rows: {cox_stack.shape[0]})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89564e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox_random = pd.read_csv(\"../data/MIMIC-ED/cox_static_random_train.csv\")\n",
    "df_cox_timevarying = pd.read_csv(\"../data/MIMIC-ED/cox_timevarying_train.csv\")\n",
    "df_cox_stacked = pd.read_csv(\"../data/MIMIC-ED/cox_static_landmark_stacked_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5da65968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['duration', 'event', 'temperature', 'heartrate', 'resprate', 'o2sat',\n",
       "       'sbp', 'dbp', 'pain', 'rhythm_flag', 'med_rn', 'gsn_rn', 'gsn',\n",
       "       'is_antibiotic', 'ndc', 'etc_rn', 'etccode', 'temperature_stay',\n",
       "       'heartrate_stay', 'resprate_stay', 'o2sat_stay', 'sbp_stay', 'dbp_stay',\n",
       "       'acuity', 'is_white', 'is_black', 'is_asian', 'is_hispanic',\n",
       "       'is_other_race', 'gender_F', 'gender_M', 'arrival_transport_AMBULANCE',\n",
       "       'arrival_transport_HELICOPTER', 'arrival_transport_OTHER',\n",
       "       'arrival_transport_UNKNOWN', 'arrival_transport_WALK IN', 'lactate',\n",
       "       'wbc', 'time_since_adm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cox_random.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cec581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for boolean columns, change them to int\n",
    "bool_cols_random = df_cox_random.select_dtypes(include=['bool']).columns\n",
    "df_cox_random[bool_cols_random] = df_cox_random[bool_cols_random].astype(int)\n",
    "bool_cols_timevarying = df_cox_timevarying.select_dtypes(include=['bool']).columns\n",
    "df_cox_timevarying[bool_cols_timevarying] = df_cox_timevarying[bool_cols_timevarying].astype(int)\n",
    "bool_cols_stacked = df_cox_stacked.select_dtypes(include=['bool']).columns\n",
    "df_cox_stacked[bool_cols_stacked] = df_cox_stacked[bool_cols_stacked].astype(int).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91712af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these back\n",
    "df_cox_random.to_csv(\"../data/MIMIC-ED/cox_static_random_train.csv\", index=False)\n",
    "df_cox_timevarying.to_csv(\"../data/MIMIC-ED/cox_timevarying_train.csv\", index=False)\n",
    "df_cox_stacked.to_csv(\"../data/MIMIC-ED/cox_static_landmark_stacked_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "769dfb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get most common gsns for septic patients\n",
    "most_common_gsns = [16599.0, 4490.0, 61716.0, 43952.0, 66419.0]\n",
    "\n",
    "# one hot encode gsn\n",
    "for gsn in most_common_gsns:\n",
    "    df_cox_random[f'gsn_{gsn}'] = (df_cox_random['gsn'] == gsn).astype(int)\n",
    "    df_cox_timevarying[f'gsn_{gsn}'] = (df_cox_timevarying['gsn'] == gsn).astype(int)\n",
    "    df_cox_stacked[f'gsn_{gsn}'] = (df_cox_stacked['gsn'] == gsn).astype(int)\n",
    "\n",
    "\n",
    "df_cox_random = df_cox_random.drop(columns=['gsn', 'gsn_rn', 'med_rn', 'is_antibiotic', 'ndc', 'etc_rn', 'etccode'])\n",
    "df_cox_timevarying = df_cox_timevarying.drop(columns=['gsn', 'gsn_rn', 'med_rn', 'is_antibiotic', 'ndc', 'etc_rn', 'etccode'])\n",
    "df_cox_stacked = df_cox_stacked.drop(columns=['gsn', 'gsn_rn', 'med_rn', 'is_antibiotic', 'ndc', 'etc_rn', 'etccode'])\n",
    "\n",
    "\n",
    "cols_to_drop = [col for col in df_cox_random.columns if col.endswith('_stay')]\n",
    "df_cox_random = df_cox_random.drop(columns=cols_to_drop)\n",
    "cols_to_drop = [col for col in df_cox_timevarying.columns if col.endswith('_stay')]\n",
    "df_cox_timevarying = df_cox_timevarying.drop(columns=cols_to_drop)\n",
    "cols_to_drop = [col for col in df_cox_stacked.columns if col.endswith('_stay')]\n",
    "df_cox_stacked = df_cox_stacked.drop(columns=cols_to_drop)\n",
    "\n",
    "# for col in df_cox_random.columns:\n",
    "#     if col.endswith('_stay'):\n",
    "#         # drop column\n",
    "# for col in df_cox_timevarying.columns:\n",
    "#     if col.endswith('_stay'):\n",
    "#         new_col = col[:-5]\n",
    "#         df_cox_timevarying.rename(columns={col: new_col}, inplace=True)\n",
    "# for col in df_cox_stacked.columns:\n",
    "#     if col.endswith('_stay'):\n",
    "#         new_col = col[:-5]\n",
    "#         df_cox_stacked.rename(columns={col: new_col}, inplace=True)\n",
    "\n",
    "\n",
    "# reorder columns\n",
    "required_cols = ['temperature', 'heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'pain', 'rhythm_flag', 'is_white', 'is_black', 'is_asian', 'is_hispanic', 'is_other_race', 'gender_F', 'gender_M', 'arrival_transport_AMBULANCE', 'arrival_transport_HELICOPTER', 'arrival_transport_OTHER', 'arrival_transport_UNKNOWN', 'arrival_transport_WALK IN', 'lactate', 'wbc', 'time_since_adm', 'gsn_16599.0', 'gsn_43952.0', 'gsn_4490.0', 'gsn_66419.0', 'gsn_61716.0']\n",
    "random_order = [\"duration\", \"event\"] + required_cols\n",
    "df_cox_random = df_cox_random[random_order]\n",
    "time_varying_order = [\"stay_id\", \"start\", \"stop\", \"event\"] + required_cols\n",
    "df_cox_timevarying = df_cox_timevarying[time_varying_order]\n",
    "stacked_order = [\"stay_id\", \"duration\", \"event\"] + required_cols\n",
    "df_cox_stacked = df_cox_stacked[stacked_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddb50982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['duration', 'event', 'temperature', 'heartrate', 'resprate', 'o2sat',\n",
      "       'sbp', 'dbp', 'pain', 'rhythm_flag', 'is_white', 'is_black', 'is_asian',\n",
      "       'is_hispanic', 'is_other_race', 'gender_F', 'gender_M',\n",
      "       'arrival_transport_AMBULANCE', 'arrival_transport_HELICOPTER',\n",
      "       'arrival_transport_OTHER', 'arrival_transport_UNKNOWN',\n",
      "       'arrival_transport_WALK IN', 'lactate', 'wbc', 'time_since_adm',\n",
      "       'gsn_16599.0', 'gsn_43952.0', 'gsn_4490.0', 'gsn_66419.0',\n",
      "       'gsn_61716.0'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# reorder columns\n",
    "required_cols = ['temperature', 'heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'pain', 'rhythm_flag', 'is_white', 'is_black', 'is_asian', 'is_hispanic', 'is_other_race', 'gender_F', 'gender_M', 'arrival_transport_AMBULANCE', 'arrival_transport_HELICOPTER', 'arrival_transport_OTHER', 'arrival_transport_UNKNOWN', 'arrival_transport_WALK IN', 'lactate', 'wbc', 'time_since_adm', 'gsn_16599.0', 'gsn_43952.0', 'gsn_4490.0', 'gsn_66419.0', 'gsn_61716.0']\n",
    "order = [\"duration\", \"event\"] + required_cols\n",
    "df_cox_random = df_cox_random[order]\n",
    "print(df_cox_random.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38a2d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these back\n",
    "df_cox_random.to_csv(\"../data/MIMIC-ED/cox_static_random_train.csv\", index=False)\n",
    "df_cox_timevarying.to_csv(\"../data/MIMIC-ED/cox_timevarying_train.csv\", index=False)\n",
    "df_cox_stacked.to_csv(\"../data/MIMIC-ED/cox_static_landmark_stacked_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c577dce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Discrete-time (bin=30m) dataset: rows=406271\n",
      "✅ Wrote ../data/MIMIC-ED/discrete_time_30min_train.csv (cols: 42, rows: 406271)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "# ----------------------------------\n",
    "# Config (adjust paths as needed)\n",
    "# ----------------------------------\n",
    "OUTPUT_PATH_DT = \"../data/MIMIC-ED/discrete_time_30min_train.csv\"\n",
    "RNG_SEED = 42  # for any optional randomness you may add later\n",
    "\n",
    "# New schema\n",
    "ID_COLS   = [\"subject_id\", \"hadm_id\", \"stay_id\", \"hadm_id_x\"]\n",
    "TIME_COLS = [\"charttime\", \"intime\", \"outtime\", \"sepsis_onset_time\"]\n",
    "\n",
    "# Labels / leak-prone columns to exclude from covariates\n",
    "LABEL_COLS = [\n",
    "    \"sepsis_dx_any\", \"sepsis_dx\",\n",
    "    \"sirs_count\", \"sirs_ge2\",\n",
    "    \"is_sepsis_onset\", \"is_sepsis\",\n",
    "    # Keep both event indicators & dx out of covariates\n",
    "]\n",
    "\n",
    "# Survival target columns\n",
    "DURATION_COL = \"duration\"  # hours (not written in output here, but kept for parity)\n",
    "EVENT_COL    = \"event\"     # 1 if event observed in this discrete bin, else 0\n",
    "\n",
    "# ----------------------------------\n",
    "# Helpers (matching your Cox utils)\n",
    "# ----------------------------------\n",
    "def _to_dt(s):\n",
    "    \"\"\"Parse to pandas datetime with coercion.\"\"\"\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "def hours_between(a, b):\n",
    "    \"\"\"Return positive hours (b - a) or NaN if any is NaT.\"\"\"\n",
    "    if pd.isna(a) or pd.isna(b):\n",
    "        return np.nan\n",
    "    return max(0.0, (b - a).total_seconds() / 3600.0)\n",
    "\n",
    "def _feature_columns(df: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"Numeric/boolean covariates only, excluding IDs/time/labels.\"\"\"\n",
    "    drop = set([c for c in ID_COLS if c in df.columns] +\n",
    "               [c for c in TIME_COLS if c in df.columns] +\n",
    "               [c for c in LABEL_COLS if c in df.columns])\n",
    "    num_cols = df.select_dtypes(include=[np.number, \"bool\"]).columns.tolist()\n",
    "    return [c for c in num_cols if c not in drop]\n",
    "\n",
    "def _stay_event_info(g: pd.DataFrame) -> Tuple[int, Optional[pd.Timestamp], Optional[pd.Timestamp]]:\n",
    "    \"\"\"\n",
    "    Return (event_flag, event_time, censor_time) where event_time/censor_time\n",
    "    are either a pandas Timestamp or None.\n",
    "    \"\"\"\n",
    "    is_event = int((g.get(\"is_sepsis\", pd.Series([0])).astype(int).max()) >= 1)\n",
    "\n",
    "    ev_times = _to_dt(g.get(\"sepsis_onset_time\"))\n",
    "    event_time = ev_times.dropna().min() if is_event == 1 else None\n",
    "    if pd.isna(event_time):\n",
    "        event_time = None\n",
    "\n",
    "    out_times = _to_dt(g.get(\"outtime\"))\n",
    "    out_time = out_times.dropna().min() if len(out_times.dropna()) else None\n",
    "\n",
    "    last_obs = _to_dt(g[\"charttime\"]).max()\n",
    "    if pd.isna(last_obs):\n",
    "        last_obs = None\n",
    "\n",
    "    if is_event == 1:\n",
    "        censor_time = None\n",
    "    else:\n",
    "        censor_time = out_time if out_time is not None else last_obs\n",
    "\n",
    "    return is_event, event_time, censor_time\n",
    "\n",
    "# ----------------------------------\n",
    "# Discrete-time person-period builder\n",
    "# ----------------------------------\n",
    "def make_discrete_time_person_period(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    id_col: str = \"stay_id\",\n",
    "    bin_minutes: int = 30,\n",
    "    hmax_hours: Optional[float] = None,\n",
    "    include_landmark_cols: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a leakage-safe discrete-time survival (person-period) dataset.\n",
    "\n",
    "    For each stay and each landmark row (a row in the raw table):\n",
    "      - Determine terminal_time = event_time (if event stay) else censor_time.\n",
    "      - Keep ONLY landmarks with charttime < terminal_time (pre-terminal, leakage-safe).\n",
    "      - Compute remaining time rem_hours = terminal_time - charttime.\n",
    "      - Discretize into fixed-width bins of `bin_minutes` (default 30 min).\n",
    "        * Event stays: create rows for k = 1..min(ceil(rem/bin), ceil(hmax/bin) if hmax)\n",
    "          and set event=1 only for the bin k == ceil(rem/bin) if the event happens\n",
    "          within the capped horizon; otherwise event=0 for all emitted bins.\n",
    "        * Censored stays: create rows for k = 1..min(floor(rem/bin), floor(hmax/bin) if hmax),\n",
    "          with event=0.\n",
    "      - Covariates for each emitted row are exactly the landmark's covariates\n",
    "        (NO carry-over or change-rate features).\n",
    "\n",
    "    Output columns:\n",
    "      - id_col\n",
    "      - t_bin (1-based bin index from the landmark)\n",
    "      - event (0/1, event happens inside this bin)\n",
    "      - [all feature columns from _feature_columns(df)]\n",
    "      - (optional) landmark meta: landmark_charttime, hours_since_intime\n",
    "\n",
    "    Notes:\n",
    "      - Requires columns: id_col, charttime, is_sepsis, and (optionally) intime/outtime/sepsis_onset_time.\n",
    "      - If `hmax_hours` is provided, the horizon is capped to that many hours.\n",
    "\n",
    "    \"\"\"\n",
    "    required = {id_col, \"charttime\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    # Prepare datetimes & sort deterministically\n",
    "    work = df.copy()\n",
    "    for c in [\"charttime\", \"intime\", \"outtime\", \"sepsis_onset_time\"]:\n",
    "        if c in work.columns:\n",
    "            work[c] = _to_dt(work[c])\n",
    "\n",
    "    work = work.dropna(subset=[\"charttime\"])\n",
    "    work = work.sort_values([id_col, \"charttime\"], kind=\"mergesort\")\n",
    "\n",
    "    feats = _feature_columns(work)\n",
    "\n",
    "    bin_hours = float(bin_minutes) / 60.0\n",
    "    rows = []\n",
    "\n",
    "    for sid, g in work.groupby(id_col, sort=False):\n",
    "        g = g.reset_index(drop=True)\n",
    "        # Terminal info (event_time or censor_time)\n",
    "        event_flag, event_time, censor_time = _stay_event_info(g)\n",
    "        terminal_time = event_time if event_flag == 1 else censor_time\n",
    "\n",
    "        if terminal_time is None:\n",
    "            # No terminal reference => cannot form durations\n",
    "            continue\n",
    "\n",
    "        # Candidate landmarks strictly before terminal_time\n",
    "        ct = g[\"charttime\"]\n",
    "        candidates = g.loc[ct < terminal_time]\n",
    "        if candidates.empty:\n",
    "            continue\n",
    "\n",
    "        # Base admission time (optional hours_since_intime calc)\n",
    "        intime = g[\"intime\"].iloc[0] if \"intime\" in g.columns else None\n",
    "\n",
    "        for _, sel in candidates.iterrows():\n",
    "            t0 = sel[\"charttime\"]\n",
    "            rem = hours_between(t0, terminal_time)\n",
    "            if not np.isfinite(rem) or rem <= 0:\n",
    "                continue\n",
    "\n",
    "            # Horizon cap in hours\n",
    "            if hmax_hours is not None:\n",
    "                rem_capped = min(rem, hmax_hours)\n",
    "            else:\n",
    "                rem_capped = rem\n",
    "\n",
    "            # Determine number of bins to emit and the \"event bin\" if applicable\n",
    "            if event_flag == 1:\n",
    "                # Event stays: event occurs in the bin where cumulative time crosses rem\n",
    "                event_bin = int(np.ceil(rem / bin_hours))\n",
    "                # Rows emitted up to the capped horizon\n",
    "                last_bin = int(np.ceil(rem_capped / bin_hours))\n",
    "                # If rem was capped below the true event bin, then this landmark contributes no event\n",
    "                for k in range(1, max(1, last_bin) + 1):\n",
    "                    y = 1 if (k == event_bin and (hmax_hours is None or k <= int(np.ceil(hmax_hours / bin_hours)))) else 0\n",
    "                    row = {\n",
    "                        id_col: sid,\n",
    "                        \"t_bin\": k,\n",
    "                        EVENT_COL: int(y),\n",
    "                    }\n",
    "                    # Attach covariates from the landmark row\n",
    "                    for c in feats:\n",
    "                        row[c] = sel.get(c, np.nan)\n",
    "\n",
    "                    if include_landmark_cols:\n",
    "                        row[\"landmark_charttime\"] = t0\n",
    "                        if intime is not None and pd.notna(intime):\n",
    "                            row[\"hours_since_intime\"] = hours_between(intime, t0)\n",
    "                    rows.append(row)\n",
    "            else:\n",
    "                # Censored stays: no event rows; emit bins fully contained in remaining time\n",
    "                last_bin = int(np.floor(rem_capped / bin_hours))\n",
    "                for k in range(1, last_bin + 1):\n",
    "                    row = {\n",
    "                        id_col: sid,\n",
    "                        \"t_bin\": k,\n",
    "                        EVENT_COL: 0,\n",
    "                    }\n",
    "                    for c in feats:\n",
    "                        row[c] = sel.get(c, np.nan)\n",
    "\n",
    "                    if include_landmark_cols:\n",
    "                        row[\"landmark_charttime\"] = t0\n",
    "                        if intime is not None and pd.notna(intime):\n",
    "                            row[\"hours_since_intime\"] = hours_between(intime, t0)\n",
    "                    rows.append(row)\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "\n",
    "    # Final tidy-up / dtype hygiene\n",
    "    if not out.empty:\n",
    "        out[EVENT_COL] = out[EVENT_COL].astype(int)\n",
    "        if \"hours_since_intime\" in out.columns:\n",
    "            out[\"hours_since_intime\"] = out[\"hours_since_intime\"].astype(float)\n",
    "\n",
    "        # sanity: event should be binary\n",
    "        if not set(out[EVENT_COL].unique()).issubset({0, 1}):\n",
    "            raise ValueError(\"event must be binary (0/1) in discrete-time data.\")\n",
    "\n",
    "        # Reorder for readability: id, landmark, t_bin, event, then features\n",
    "        base_cols = [c for c in [id_col, \"landmark_charttime\", \"hours_since_intime\", \"t_bin\", EVENT_COL]\n",
    "                     if c in out.columns]\n",
    "        feat_cols = [c for c in _feature_columns(out) if c not in base_cols]\n",
    "        out = out[base_cols + feat_cols]\n",
    "\n",
    "    print(f\"[OK] Discrete-time (bin={bin_minutes}m) dataset: rows={len(out)}\")\n",
    "    return out\n",
    "\n",
    "def make_discrete_time_person_period_fast(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    id_col: str = \"stay_id\",\n",
    "    bin_minutes: int = 30,\n",
    "    hmax_hours: float | None = None,\n",
    "    include_landmark_cols: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    req = {id_col, \"charttime\", \"is_sepsis\"}\n",
    "    miss = req - set(df.columns)\n",
    "    if miss:\n",
    "        raise ValueError(f\"Missing required columns: {miss}\")\n",
    "\n",
    "    work = df.copy()\n",
    "    for c in [\"charttime\", \"intime\", \"outtime\", \"sepsis_onset_time\"]:\n",
    "        if c in work.columns:\n",
    "            work[c] = pd.to_datetime(work[c], errors=\"coerce\")\n",
    "    work = work.dropna(subset=[\"charttime\"])\n",
    "    work = work.sort_values([id_col, \"charttime\"], kind=\"mergesort\")\n",
    "\n",
    "    feats = _feature_columns(work)\n",
    "    bin_h = float(bin_minutes) / 60.0\n",
    "\n",
    "    # ---------- stay-level terminal times (vectorized) ----------\n",
    "    # event per stay\n",
    "    is_event = (work.groupby(id_col)[\"is_sepsis\"]\n",
    "                .transform(lambda s: int(s.astype(int).max() >= 1)))\n",
    "    work[\"_is_event\"] = is_event\n",
    "\n",
    "    # event_time = min non-null sepsis_onset_time per stay (if event)\n",
    "    if \"sepsis_onset_time\" in work.columns:\n",
    "        ev_time = (work.groupby(id_col)[\"sepsis_onset_time\"]\n",
    "                   .transform(lambda s: s.dropna().min() if s.notna().any() else pd.NaT))\n",
    "    else:\n",
    "        ev_time = pd.Series(pd.NaT, index=work.index)\n",
    "\n",
    "    # out_time = min non-null outtime per stay\n",
    "    if \"outtime\" in work.columns:\n",
    "        out_time = (work.groupby(id_col)[\"outtime\"]\n",
    "                    .transform(lambda s: s.dropna().min() if s.notna().any() else pd.NaT))\n",
    "    else:\n",
    "        out_time = pd.Series(pd.NaT, index=work.index)\n",
    "\n",
    "    # last observed time per stay\n",
    "    last_obs = work.groupby(id_col)[\"charttime\"].transform(\"max\")\n",
    "\n",
    "    # terminal time per row\n",
    "    term_time = ev_time.where(is_event == 1, out_time.fillna(last_obs))\n",
    "    work[\"_terminal_time\"] = term_time\n",
    "\n",
    "    # leakage-safe landmarks\n",
    "    mask_ok = work[\"_terminal_time\"].notna() & (work[\"charttime\"] < work[\"_terminal_time\"])\n",
    "    L = work.loc[mask_ok, [id_col, \"charttime\", \"_terminal_time\", \"_is_event\"] + feats].copy()\n",
    "\n",
    "    if L.empty:\n",
    "        return pd.DataFrame(columns=[id_col, \"t_bin\", EVENT_COL] + feats)\n",
    "\n",
    "    # ---------- remaining time & bin counts (vectorized) ----------\n",
    "    rem_h = (L[\"_terminal_time\"] - L[\"charttime\"]).dt.total_seconds() / 3600.0\n",
    "    if hmax_hours is not None:\n",
    "        rem_cap = np.minimum(rem_h, hmax_hours)\n",
    "    else:\n",
    "        rem_cap = rem_h\n",
    "\n",
    "    # event and censor bin counts\n",
    "    event_bin = np.ceil(rem_h / bin_h).astype(\"int64\")          # where event exists\n",
    "    last_bin_ev = np.ceil(rem_cap / bin_h).astype(\"int64\")      # emitted for event stays\n",
    "    last_bin_ce = np.floor(rem_cap / bin_h).astype(\"int64\")     # emitted for censored stays\n",
    "\n",
    "    is_ev = L[\"_is_event\"].to_numpy().astype(bool)\n",
    "    # number of bins to emit per landmark row\n",
    "    n_bins = np.where(is_ev, np.maximum(1, last_bin_ev), np.maximum(0, last_bin_ce))\n",
    "\n",
    "    # drop rows emitting zero bins (censored too close to terminal)\n",
    "    keep = n_bins > 0\n",
    "    if not np.any(keep):\n",
    "        return pd.DataFrame(columns=[id_col, \"t_bin\", EVENT_COL] + feats)\n",
    "    L = L.loc[keep].reset_index(drop=True)\n",
    "    n_bins = n_bins[keep]\n",
    "    is_ev = is_ev[keep]\n",
    "    event_bin = event_bin[keep]\n",
    "    last_bin_ev = last_bin_ev[keep]\n",
    "    last_bin_ce = last_bin_ce[keep]\n",
    "\n",
    "    # ---------- explode bins in NumPy ----------\n",
    "    # build t_bin per row: 1..n_bins[i]\n",
    "    tbin = np.concatenate([np.arange(1, nb + 1, dtype=np.int32) for nb in n_bins])\n",
    "\n",
    "    # repeat metadata/covariates\n",
    "    reps = n_bins.astype(int)\n",
    "    ids_rep = np.repeat(L[id_col].to_numpy(), reps)\n",
    "    feat_mat = np.column_stack([np.repeat(L[c].to_numpy(), reps) for c in feats]) if feats else None\n",
    "\n",
    "    # event flag per emitted row\n",
    "    # event rows: k == event_bin and k <= last_bin_ev\n",
    "    ev_idx = np.repeat(is_ev, reps)\n",
    "    eb_rep  = np.repeat(event_bin, reps)\n",
    "    lbev_rep = np.repeat(last_bin_ev, reps)\n",
    "    lbc_rep = np.repeat(last_bin_ce, reps)  # for completeness; not used directly\n",
    "\n",
    "    event_vec = np.zeros_like(tbin, dtype=np.int8)\n",
    "    # event only possible on event stays\n",
    "    mask_e = ev_idx & (tbin == eb_rep) & (tbin <= lbev_rep)\n",
    "    event_vec[mask_e] = 1\n",
    "\n",
    "    out_cols = [id_col, \"t_bin\", EVENT_COL] + feats\n",
    "    data = {\n",
    "        id_col: ids_rep,\n",
    "        \"t_bin\": tbin,\n",
    "        EVENT_COL: event_vec,\n",
    "    }\n",
    "    for j, c in enumerate(feats):\n",
    "        data[c] = feat_mat[:, j] if feat_mat is not None else np.array([], dtype=float)\n",
    "\n",
    "    out = pd.DataFrame(data)\n",
    "\n",
    "    if include_landmark_cols:\n",
    "        # optional metadata to help analysis/debug; kept aligned via repeat\n",
    "        lm_time = np.repeat(L[\"charttime\"].to_numpy(), reps)\n",
    "        data_meta = {\"landmark_charttime\": lm_time}\n",
    "        if \"intime\" in work.columns:\n",
    "            # hours since intime if available\n",
    "            intime_stay = work.groupby(id_col)[\"intime\"].transform(\"first\")\n",
    "            L_intime = intime_stay.loc[L.index].to_numpy()\n",
    "            hs = (lm_time - np.repeat(L_intime, reps)).astype(\"timedelta64[s]\").astype(\"float64\") / 3600.0\n",
    "            data_meta[\"hours_since_intime\"] = hs\n",
    "        out = pd.concat([pd.DataFrame(data_meta), out], axis=1)\n",
    "\n",
    "    # tidy dtypes / order\n",
    "    out[EVENT_COL] = out[EVENT_COL].astype(int)\n",
    "    base = [c for c in [\"landmark_charttime\", \"hours_since_intime\"] if c in out.columns]\n",
    "    out = out[base + [id_col, \"t_bin\", EVENT_COL] + feats]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# Main\n",
    "# ----------------------------------\n",
    "def main():\n",
    "    # Example expects a dataframe named df with required columns present.\n",
    "    # Replace this with your actual load pipeline.\n",
    "    # df = pd.read_csv(\"path/to/your/source.csv\", parse_dates=[\"charttime\",\"intime\",\"outtime\",\"sepsis_onset_time\"])\n",
    "    # For illustration only, we assume `df` is already in scope.\n",
    "    df = df_small\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    need = {\"stay_id\", \"charttime\", \"is_sepsis\"}\n",
    "    missing = need - set(df.columns)\n",
    "    if missing:\n",
    "        raise FileNotFoundError(f\"Input missing required columns: {missing}\")\n",
    "\n",
    "    # Build discrete-time table with 30-minute bins; optionally cap horizon (e.g., hmax_hours=6.0)\n",
    "    dt_df = make_discrete_time_person_period(\n",
    "        df,\n",
    "        id_col=\"stay_id\",\n",
    "        bin_minutes=30,\n",
    "        hmax_hours=None,            # set e.g. 6.0 to cap at 6 hours\n",
    "        include_landmark_cols=True, # keep helpful landmark metadata\n",
    "    )\n",
    "\n",
    "    Path(OUTPUT_PATH_DT).parent.mkdir(parents=True, exist_ok=True)\n",
    "    dt_df.to_csv(OUTPUT_PATH_DT, index=False)\n",
    "    print(f\"✅ Wrote {OUTPUT_PATH_DT} (cols: {dt_df.shape[1]}, rows: {dt_df.shape[0]})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53eb7bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discrete = pd.read_csv(\"../data/MIMIC-ED/discrete_time_30min_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ea9995d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stay_id', 'landmark_charttime', 'hours_since_intime', 't_bin', 'event',\n",
       "       'temperature', 'heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'pain',\n",
       "       'rhythm_flag', 'med_rn', 'gsn_rn', 'gsn', 'is_antibiotic', 'ndc',\n",
       "       'etc_rn', 'etccode', 'temperature_stay', 'heartrate_stay',\n",
       "       'resprate_stay', 'o2sat_stay', 'sbp_stay', 'dbp_stay', 'acuity',\n",
       "       'is_white', 'is_black', 'is_asian', 'is_hispanic', 'is_other_race',\n",
       "       'gender_F', 'gender_M', 'arrival_transport_AMBULANCE',\n",
       "       'arrival_transport_HELICOPTER', 'arrival_transport_OTHER',\n",
       "       'arrival_transport_UNKNOWN', 'arrival_transport_WALK IN', 'lactate',\n",
       "       'wbc', 'time_since_adm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_discrete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0360d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for boolean columns, change them to int\n",
    "bool_cols_random = df_discrete.select_dtypes(include=['bool']).columns\n",
    "df_discrete[bool_cols_random] = df_discrete[bool_cols_random].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "434ec404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these back\n",
    "df_discrete.to_csv(\"../data/MIMIC-ED/discrete_time_30min_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd10ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get most common gsns for septic patients\n",
    "most_common_gsns = [16599.0, 4490.0, 61716.0, 43952.0, 66419.0]\n",
    "\n",
    "# one hot encode gsn\n",
    "for gsn in most_common_gsns:\n",
    "    df_discrete[f'gsn_{gsn}'] = (df_discrete['gsn'] == gsn).astype(int)\n",
    "\n",
    "\n",
    "df_discrete = df_discrete.drop(columns=['gsn', 'gsn_rn', 'med_rn', 'is_antibiotic', 'ndc', 'etc_rn', 'etccode'])\n",
    "\n",
    "\n",
    "\n",
    "cols_to_drop = [col for col in df_discrete.columns if col.endswith('_stay')]\n",
    "df_discrete = df_discrete.drop(columns=cols_to_drop)\n",
    "\n",
    "# reorder columns\n",
    "required_cols = ['temperature', 'heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'pain', 'rhythm_flag', 'is_white', 'is_black', 'is_asian', 'is_hispanic', 'is_other_race', 'gender_F', 'gender_M', 'arrival_transport_AMBULANCE', 'arrival_transport_HELICOPTER', 'arrival_transport_OTHER', 'arrival_transport_UNKNOWN', 'arrival_transport_WALK IN', 'lactate', 'wbc', 'time_since_adm', 'gsn_16599.0', 'gsn_43952.0', 'gsn_4490.0', 'gsn_66419.0', 'gsn_61716.0']\n",
    "discrete_order = ['stay_id', 'landmark_charttime', 'hours_since_intime', 't_bin', 'event'] + required_cols\n",
    "df_discrete = df_discrete[discrete_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dede4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these back\n",
    "df_discrete.to_csv(\"../data/MIMIC-ED/discrete_time_30min_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62413d48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sepsis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
