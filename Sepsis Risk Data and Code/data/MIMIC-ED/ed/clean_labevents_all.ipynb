{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "386a721b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final columns after collapsing/merging:\n",
      "['subject_id', 'hadm_id', 'stay_id', 'storetime', 'Lactate', 'Bilirubin, Direct', 'Bilirubin, Total', 'Creatinine', 'D-Dimer', 'Absolute Lymphocyte Count', 'Atypical Lymphocytes', 'Bands', 'Basophils', 'Eosinophil Count', 'Eosinophils', 'INR(PT)', 'Lymphocytes', 'Lymphocytes, Percent', 'Monocyte Count', 'Monocytes', 'Neutrophils', 'Platelet Count', 'PTT', 'Absolute Basophil Count', 'Absolute Eosinophil Count', 'Absolute Monocyte Count', 'Fibrinogen', 'Immature Granulocytes', 'Absolute Other WBC', 'WBC', 'CRP', 'ANC']\n",
      "\n",
      "Missingness % for lab columns (sorted):\n",
      "Creatinine                    71.218206\n",
      "WBC                           73.226238\n",
      "Platelet Count                73.360107\n",
      "Basophils                     75.100402\n",
      "Eosinophils                   75.100402\n",
      "Lymphocytes                   75.100402\n",
      "Neutrophils                   75.100402\n",
      "Monocytes                     75.100402\n",
      "Lactate                       82.998661\n",
      "INR(PT)                       83.132530\n",
      "PTT                           83.266399\n",
      "Absolute Lymphocyte Count     84.471218\n",
      "Absolute Monocyte Count       84.605087\n",
      "Absolute Eosinophil Count     84.605087\n",
      "Absolute Basophil Count       84.605087\n",
      "ANC                           84.605087\n",
      "Immature Granulocytes         88.085676\n",
      "Bilirubin, Total              89.290495\n",
      "Atypical Lymphocytes          96.385542\n",
      "Bands                         96.921017\n",
      "Bilirubin, Direct             99.464525\n",
      "D-Dimer                       99.598394\n",
      "CRP                           99.866131\n",
      "Lymphocytes, Percent          99.866131\n",
      "Eosinophil Count             100.000000\n",
      "Fibrinogen                   100.000000\n",
      "Absolute Other WBC           100.000000\n",
      "Monocyte Count               100.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>storetime</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>Bilirubin, Direct</th>\n",
       "      <th>Bilirubin, Total</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>D-Dimer</th>\n",
       "      <th>Absolute Lymphocyte Count</th>\n",
       "      <th>...</th>\n",
       "      <th>PTT</th>\n",
       "      <th>Absolute Basophil Count</th>\n",
       "      <th>Absolute Eosinophil Count</th>\n",
       "      <th>Absolute Monocyte Count</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Immature Granulocytes</th>\n",
       "      <th>Absolute Other WBC</th>\n",
       "      <th>WBC</th>\n",
       "      <th>CRP</th>\n",
       "      <th>ANC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33258284</td>\n",
       "      <td>2180-05-06 22:42:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33258284</td>\n",
       "      <td>2180-05-06 23:13:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33258284</td>\n",
       "      <td>2180-05-06 23:14:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>30.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33258284</td>\n",
       "      <td>2180-05-06 23:16:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38112554</td>\n",
       "      <td>2180-06-26 16:40:00</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>10040025</td>\n",
       "      <td>27996268.0</td>\n",
       "      <td>36041505</td>\n",
       "      <td>2148-01-22 16:41:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>53.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>10040025</td>\n",
       "      <td>27996268.0</td>\n",
       "      <td>36041505</td>\n",
       "      <td>2148-01-22 16:54:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>10040025</td>\n",
       "      <td>27996268.0</td>\n",
       "      <td>36041505</td>\n",
       "      <td>2148-01-22 17:18:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>10040025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36041505</td>\n",
       "      <td>2148-01-23 10:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>10040025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36041505</td>\n",
       "      <td>2148-01-23 10:57:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>55.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>747 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject_id     hadm_id   stay_id            storetime  Lactate  \\\n",
       "0      10000032         NaN  33258284  2180-05-06 22:42:00      NaN   \n",
       "1      10000032         NaN  33258284  2180-05-06 23:13:00      NaN   \n",
       "2      10000032         NaN  33258284  2180-05-06 23:14:00      NaN   \n",
       "3      10000032         NaN  33258284  2180-05-06 23:16:00      NaN   \n",
       "4      10000032         NaN  38112554  2180-06-26 16:40:00      1.7   \n",
       "..          ...         ...       ...                  ...      ...   \n",
       "742    10040025  27996268.0  36041505  2148-01-22 16:41:00      NaN   \n",
       "743    10040025  27996268.0  36041505  2148-01-22 16:54:00      NaN   \n",
       "744    10040025  27996268.0  36041505  2148-01-22 17:18:00      NaN   \n",
       "745    10040025         NaN  36041505  2148-01-23 10:51:00      NaN   \n",
       "746    10040025         NaN  36041505  2148-01-23 10:57:00      NaN   \n",
       "\n",
       "     Bilirubin, Direct  Bilirubin, Total  Creatinine  D-Dimer  \\\n",
       "0                  NaN               NaN         NaN      NaN   \n",
       "1                  NaN               NaN         NaN      NaN   \n",
       "2                  NaN               NaN         NaN      NaN   \n",
       "3                  NaN               1.6         0.3      NaN   \n",
       "4                  NaN               NaN         NaN      NaN   \n",
       "..                 ...               ...         ...      ...   \n",
       "742                NaN               NaN         NaN      NaN   \n",
       "743                NaN               NaN         NaN      NaN   \n",
       "744                NaN               NaN         1.8      NaN   \n",
       "745                NaN               NaN         NaN      NaN   \n",
       "746                NaN               NaN         NaN      NaN   \n",
       "\n",
       "     Absolute Lymphocyte Count  ...   PTT  Absolute Basophil Count  \\\n",
       "0                          NaN  ...   NaN                      NaN   \n",
       "1                          NaN  ...   NaN                      NaN   \n",
       "2                          NaN  ...  30.9                      NaN   \n",
       "3                          NaN  ...   NaN                      NaN   \n",
       "4                          NaN  ...   NaN                      NaN   \n",
       "..                         ...  ...   ...                      ...   \n",
       "742                        NaN  ...  53.7                      NaN   \n",
       "743                       0.26  ...   NaN                      0.0   \n",
       "744                        NaN  ...   NaN                      NaN   \n",
       "745                        NaN  ...   NaN                      NaN   \n",
       "746                        NaN  ...  55.1                      NaN   \n",
       "\n",
       "     Absolute Eosinophil Count  Absolute Monocyte Count  Fibrinogen  \\\n",
       "0                          NaN                      NaN         NaN   \n",
       "1                          NaN                      NaN         NaN   \n",
       "2                          NaN                      NaN         NaN   \n",
       "3                          NaN                      NaN         NaN   \n",
       "4                          NaN                      NaN         NaN   \n",
       "..                         ...                      ...         ...   \n",
       "742                        NaN                      NaN         NaN   \n",
       "743                       0.09                     0.78         NaN   \n",
       "744                        NaN                      NaN         NaN   \n",
       "745                        NaN                      NaN         NaN   \n",
       "746                        NaN                      NaN         NaN   \n",
       "\n",
       "     Immature Granulocytes  Absolute Other WBC  WBC  CRP   ANC  \n",
       "0                      NaN                 NaN  5.0  NaN   NaN  \n",
       "1                      NaN                 NaN  NaN  NaN   NaN  \n",
       "2                      NaN                 NaN  NaN  NaN   NaN  \n",
       "3                      NaN                 NaN  NaN  NaN   NaN  \n",
       "4                      NaN                 NaN  NaN  NaN   NaN  \n",
       "..                     ...                 ...  ...  ...   ...  \n",
       "742                    NaN                 NaN  NaN  NaN   NaN  \n",
       "743                    NaN                 NaN  NaN  NaN  7.57  \n",
       "744                    NaN                 NaN  NaN  NaN   NaN  \n",
       "745                    NaN                 NaN  NaN  NaN   NaN  \n",
       "746                    NaN                 NaN  NaN  NaN   NaN  \n",
       "\n",
       "[747 rows x 32 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"cleaned_labevents.csv\")\n",
    "\n",
    "# Columns you never want to collapse (keep as-is)\n",
    "id_cols = [c for c in [\"subject_id\", \"hadm_id\", \"stay_id\", \"storetime\", \"charttime\"] if c in df.columns]\n",
    "\n",
    "# Build groups by \"base name\" (strip trailing .<number>)\n",
    "groups = {}\n",
    "for col in df.columns:\n",
    "    if col in id_cols:\n",
    "        continue\n",
    "    base = re.sub(r\"\\.\\d+$\", \"\", col)  # \"Lactate.2\" -> \"Lactate\"\n",
    "    groups.setdefault(base, []).append(col)\n",
    "\n",
    "# Collapse duplicates: base column becomes first non-null across its group\n",
    "for base, cols in groups.items():\n",
    "    if len(cols) <= 1:\n",
    "        continue\n",
    "\n",
    "    # Keep a stable order: base first (if present), then .1, .2...\n",
    "    cols_sorted = sorted(\n",
    "        cols,\n",
    "        key=lambda x: (0 if x == base else 1, int(x.split(\".\")[-1]) if \".\" in x else 0)\n",
    "    )\n",
    "\n",
    "    df[base] = df[cols_sorted].bfill(axis=1).iloc[:, 0]  # first non-null across cols\n",
    "    df.drop(columns=[c for c in cols_sorted if c != base], inplace=True)\n",
    "\n",
    "# ---- Now merge true synonyms (from your second cell) ----\n",
    "def merge_columns_inplace(df, cols, new_name):\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    if len(cols) == 0:\n",
    "        return\n",
    "    df[new_name] = df[cols].bfill(axis=1).iloc[:, 0]\n",
    "    df.drop(columns=cols, inplace=True)\n",
    "\n",
    "merge_columns_inplace(df, [\"WBC Count\", \"White Blood Cells\"], \"WBC\")\n",
    "merge_columns_inplace(df, [\"C-Reactive Protein\", \"High-Sensitivity CRP\"], \"CRP\")\n",
    "merge_columns_inplace(df, [\"Absolute Neutrophil Count\", \"Absolute Neutrophil\"], \"ANC\")\n",
    "\n",
    "# ---- Define lab_cols and check missingness ----\n",
    "# Select numeric lab columns (exclude IDs and timestamps)\n",
    "lab_cols = [c for c in df.select_dtypes(include=[float, int]).columns if c not in ['subject_id', 'hadm_id', 'stay_id']]\n",
    "\n",
    "print(\"Final columns after collapsing/merging:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "missing_pct = df[lab_cols].isnull().mean() * 100\n",
    "print(\"\\nMissingness % for lab columns (sorted):\")\n",
    "print(missing_pct.sort_values())\n",
    "\n",
    "# Optional: Display df\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a31f561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final columns:\n",
      "['subject_id', 'hadm_id', 'stay_id', 'storetime', 'Lactate', 'Bilirubin, Direct', 'Bilirubin, Total', 'Creatinine', 'D-Dimer', 'Absolute Lymphocyte Count', 'Atypical Lymphocytes', 'Bands', 'Basophils', 'Eosinophil Count', 'Eosinophils', 'INR(PT)', 'Lymphocytes', 'Lymphocytes, Percent', 'Monocyte Count', 'Monocytes', 'Neutrophils', 'Platelet Count', 'PTT', 'Absolute Basophil Count', 'Absolute Eosinophil Count', 'Absolute Monocyte Count', 'Fibrinogen', 'Immature Granulocytes', 'Absolute Other WBC', 'WBC', 'CRP', 'ANC']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def merge_columns_inplace(df, cols, new_name):\n",
    "    \"\"\"\n",
    "    Merge multiple synonymous columns into one using first non-null value.\n",
    "    Operates IN PLACE on the dataframe.\n",
    "    \"\"\"\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    if len(cols) == 0:\n",
    "        return\n",
    "\n",
    "    df[new_name] = df[cols].bfill(axis=1).iloc[:, 0]\n",
    "    df.drop(columns=cols, inplace=True)\n",
    "\n",
    "\n",
    "# ---- merge true synonyms ----\n",
    "merge_columns_inplace(df, [\"WBC Count\", \"White Blood Cells\"], \"WBC\")\n",
    "merge_columns_inplace(df, [\"C-Reactive Protein\", \"High-Sensitivity CRP\"], \"CRP\")\n",
    "merge_columns_inplace(df, [\"Absolute Neutrophil Count\", \"Absolute Neutrophil\"], \"ANC\")\n",
    "\n",
    "# optional: quick sanity check\n",
    "print(\"Final columns:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d1cd0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of cleaned DataFrame: (612, 13)\n",
      "Sample rows:\n",
      "   subject_id  hadm_id   stay_id            storetime  Creatinine  \\\n",
      "0    10000032      NaN  33258284  2180-05-06 22:42:00         NaN   \n",
      "1    10000032      NaN  33258284  2180-05-06 23:13:00         NaN   \n",
      "2    10000032      NaN  33258284  2180-05-06 23:14:00         NaN   \n",
      "3    10000032      NaN  33258284  2180-05-06 23:16:00         0.3   \n",
      "5    10000032      NaN  38112554  2180-06-26 16:50:00         NaN   \n",
      "\n",
      "   Platelet Count  Absolute Neutrophil Count  C-Reactive Protein  INR(PT)  \\\n",
      "0            71.0                        NaN                 NaN      NaN   \n",
      "1             NaN                        NaN                 NaN      1.6   \n",
      "2             NaN                        NaN                 NaN      NaN   \n",
      "3             NaN                        NaN                 NaN      NaN   \n",
      "5           143.0                        NaN                 NaN      NaN   \n",
      "\n",
      "    PTT  Fibrinogen  Bilirubin, Total  D-Dimer  \n",
      "0   NaN         NaN               NaN      NaN  \n",
      "1   NaN         NaN               NaN      NaN  \n",
      "2  30.9         NaN               NaN      NaN  \n",
      "3   NaN         NaN               1.6      NaN  \n",
      "5   NaN         NaN               NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the raw lab events CSV\n",
    "df = pd.read_csv('/Users/ebiteclement/Documents/Beyond-Time-Zero/Sepsis Risk Data and Code/data/MIMIC-ED/ed/cleaned_labevents.csv')\n",
    "\n",
    "# Select the relevant columns: subject_id, hadm_id, stay_id, storetime, and the specified labs\n",
    "# Note: Using exact column names from the header\n",
    "selected_columns = [\n",
    "    'subject_id', 'hadm_id', 'stay_id', 'storetime',\n",
    "    'Creatinine',                 # Creatinine\n",
    "    'Platelet Count',            # Platelet Count\n",
    "    'Absolute Neutrophil Count',  # ANC\n",
    "    'C-Reactive Protein',         # CRP\n",
    "    'INR(PT)',                    # INR\n",
    "    'PTT',                        # PTT\n",
    "    'Fibrinogen',                 # Fibrinogen\n",
    "    'Bilirubin, Total',           # Bilirubin\n",
    "    'D-Dimer'                     # D-Dimer\n",
    "]\n",
    "\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "# Drop rows where all lab columns are NaN\n",
    "lab_columns = ['Creatinine', 'Platelet Count','Absolute Neutrophil Count', 'C-Reactive Protein', 'INR(PT)', 'PTT', 'Fibrinogen', 'Bilirubin, Total', 'D-Dimer']\n",
    "df_clean = df_selected.dropna(subset=lab_columns, how='all')\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_path = '/Users/ebiteclement/Documents/Beyond-Time-Zero/Sepsis Risk Data and Code/data/MIMIC-ED/ed/cleaned_labevents_additional_labs.csv'\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "\n",
    "# Print shape and a sample for verification\n",
    "print(f\"Shape of cleaned DataFrame: {df_clean.shape}\")\n",
    "print(\"Sample rows:\")\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1076b33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        stay_id     start      stop  event  temperature  heartrate  resprate  \\\n",
      "0      30005196  0.000000  0.066667      0         97.8       86.0      16.0   \n",
      "1      30005196  0.066667  0.150000      0         97.8       86.0      16.0   \n",
      "2      30005196  0.150000  0.400000      0         97.8       85.0      29.0   \n",
      "3      30005196  0.400000  0.600000      0         97.8       84.0      28.0   \n",
      "4      30005196  0.600000  0.933333      0         97.9       83.0      22.0   \n",
      "...         ...       ...       ...    ...          ...        ...       ...   \n",
      "22709  39999835  6.533333  6.816667      0         98.0      130.0      18.0   \n",
      "22710  39999835  6.816667  6.900000      0         98.0      130.0      18.0   \n",
      "22711  39999835  6.900000  8.050000      0         98.0       80.0      18.0   \n",
      "22712  39999835  8.050000  8.966667      0         98.5      118.0      18.0   \n",
      "22713  39999835  8.966667  9.250000      0         98.5      118.0      18.0   \n",
      "\n",
      "       o2sat    sbp   dbp  ...  arrival_transport_UNKNOWN  \\\n",
      "0       97.0  130.0  94.0  ...                      False   \n",
      "1       97.0  130.0  94.0  ...                      False   \n",
      "2       95.0  109.0  50.0  ...                      False   \n",
      "3       95.0  122.0  60.0  ...                      False   \n",
      "4       95.0  107.0  52.0  ...                      False   \n",
      "...      ...    ...   ...  ...                        ...   \n",
      "22709   99.0  122.0  65.0  ...                      False   \n",
      "22710   99.0  122.0  65.0  ...                      False   \n",
      "22711  100.0  133.0  54.0  ...                      False   \n",
      "22712   96.0  146.0  75.0  ...                      False   \n",
      "22713   96.0  146.0  75.0  ...                      False   \n",
      "\n",
      "       arrival_transport_WALK IN  lactate  wbc  time_since_adm  gsn_16599.0  \\\n",
      "0                          False      1.6  7.8        0.000000            1   \n",
      "1                          False      1.6  7.8        0.066667            0   \n",
      "2                          False      1.6  7.8        0.150000            0   \n",
      "3                          False      1.6  7.8        0.400000            0   \n",
      "4                          False      1.4  7.8        0.600000            0   \n",
      "...                          ...      ...  ...             ...          ...   \n",
      "22709                      False      1.6  5.7        6.533333            0   \n",
      "22710                      False      1.6  5.7        6.816667            0   \n",
      "22711                      False      1.6  5.7        6.900000            0   \n",
      "22712                      False      1.6  5.7        8.050000            0   \n",
      "22713                      False      1.6  5.7        8.966667            0   \n",
      "\n",
      "       gsn_43952.0  gsn_4490.0  gsn_66419.0  gsn_61716.0  \n",
      "0                0           0            0            0  \n",
      "1                0           0            1            0  \n",
      "2                0           0            1            0  \n",
      "3                0           0            1            0  \n",
      "4                0           0            1            0  \n",
      "...            ...         ...          ...          ...  \n",
      "22709            0           0            0            0  \n",
      "22710            0           0            0            0  \n",
      "22711            0           0            0            0  \n",
      "22712            0           0            0            0  \n",
      "22713            0           0            0            0  \n",
      "\n",
      "[22714 rows x 32 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8f/kxlnf3g53wj89hjnj3tff1740000gn/T/ipykernel_2372/3607548295.py:61: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cox_df = cox_df.groupby(\"stay_id\", group_keys=False).apply(merge_for_group)\n",
      "/var/folders/8f/kxlnf3g53wj89hjnj3tff1740000gn/T/ipykernel_2372/3607548295.py:61: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cox_df = cox_df.groupby(\"stay_id\", group_keys=False).apply(merge_for_group)\n",
      "/var/folders/8f/kxlnf3g53wj89hjnj3tff1740000gn/T/ipykernel_2372/3607548295.py:61: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cox_df = cox_df.groupby(\"stay_id\", group_keys=False).apply(merge_for_group)\n",
      "/var/folders/8f/kxlnf3g53wj89hjnj3tff1740000gn/T/ipykernel_2372/3607548295.py:61: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cox_df = cox_df.groupby(\"stay_id\", group_keys=False).apply(merge_for_group)\n",
      "/var/folders/8f/kxlnf3g53wj89hjnj3tff1740000gn/T/ipykernel_2372/3607548295.py:61: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cox_df = cox_df.groupby(\"stay_id\", group_keys=False).apply(merge_for_group)\n",
      "/var/folders/8f/kxlnf3g53wj89hjnj3tff1740000gn/T/ipykernel_2372/3607548295.py:61: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cox_df = cox_df.groupby(\"stay_id\", group_keys=False).apply(merge_for_group)\n",
      "/var/folders/8f/kxlnf3g53wj89hjnj3tff1740000gn/T/ipykernel_2372/3607548295.py:61: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cox_df = cox_df.groupby(\"stay_id\", group_keys=False).apply(merge_for_group)\n",
      "/var/folders/8f/kxlnf3g53wj89hjnj3tff1740000gn/T/ipykernel_2372/3607548295.py:61: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cox_df = cox_df.groupby(\"stay_id\", group_keys=False).apply(merge_for_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved updated cox_timevarying to /Users/ebiteclement/Documents/Beyond-Time-Zero/Sepsis Risk Data and Code/data/MIMIC-ED/cox_timevarying_with_all_labs_train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8f/kxlnf3g53wj89hjnj3tff1740000gn/T/ipykernel_2372/3607548295.py:61: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cox_df = cox_df.groupby(\"stay_id\", group_keys=False).apply(merge_for_group)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths (hardcoded for notebook; adjust if needed)\n",
    "REPO_ROOT = Path(\"/Users/ebiteclement/Documents/Beyond-Time-Zero/Sepsis Risk Data and Code\")\n",
    "DATA_DIR = REPO_ROOT / \"data\" / \"MIMIC-ED\"\n",
    "ED_DIR = DATA_DIR / \"ed\"\n",
    "\n",
    "cox_path = DATA_DIR / \"cox_timevarying_train.csv\"  # Load the one with Creatinine and Platelet Count already added\n",
    "labs_path = ED_DIR / \"cleaned_labevents_additional_labs.csv\"  # The new labs CSV\n",
    "edstays_path = ED_DIR / \"edstays.csv\"\n",
    "output_path = DATA_DIR / \"cox_timevarying_with_all_labs_train.csv\"  # New output with all labs\n",
    "\n",
    "# Load edstays for intime\n",
    "edstays = pd.read_csv(edstays_path, usecols=['stay_id', 'intime'])\n",
    "edstays['intime'] = pd.to_datetime(edstays['intime'])\n",
    "edstays = edstays.set_index('stay_id')['intime']\n",
    "\n",
    "# Load labs\n",
    "labs = pd.read_csv(labs_path)\n",
    "labs['storetime'] = pd.to_datetime(labs['storetime'])\n",
    "labs = labs.dropna(subset=['stay_id', 'storetime']).copy()\n",
    "\n",
    "# Compute hours_since_adm\n",
    "labs = labs.merge(edstays, left_on='stay_id', right_index=True, how='left')\n",
    "labs['hours_since_adm'] = (labs['storetime'] - labs['intime']).dt.total_seconds() / 3600\n",
    "labs = labs.drop(columns=['intime', 'storetime', 'subject_id', 'hadm_id'])  # drop unnecessary\n",
    "\n",
    "# Select the new lab columns\n",
    "lab_cols = ['Creatinine', 'Platelet Count', 'Absolute Neutrophil Count', 'C-Reactive Protein', 'INR(PT)', 'PTT', 'Fibrinogen', 'Bilirubin, Total', 'D-Dimer']\n",
    "\n",
    "# Keep only relevant columns\n",
    "labs = labs[['stay_id', 'hours_since_adm'] + lab_cols].dropna(subset=['hours_since_adm'])\n",
    "\n",
    "# Sort labs by stay_id and time\n",
    "labs = labs.sort_values(['stay_id', 'hours_since_adm'])\n",
    "\n",
    "# Load cox data (already has Creatinine and Platelet Count)\n",
    "cox_df = pd.read_csv(cox_path)\n",
    "print(cox_df)\n",
    "\n",
    "# For each lab column, merge using groupby to avoid sorting issues\n",
    "for lab_col in lab_cols:\n",
    "    temp_labs = labs[['stay_id', 'hours_since_adm', lab_col]].dropna(subset=[lab_col])\n",
    "    \n",
    "    def merge_for_group(group):\n",
    "        stay_labs = temp_labs[temp_labs['stay_id'] == group.name].sort_values('hours_since_adm')\n",
    "        stay_labs = stay_labs.drop(columns=['stay_id'])  # Avoid suffix on stay_id\n",
    "        if lab_col in group.columns:\n",
    "            group = group.drop(columns=[lab_col])  # Avoid suffix on lab_col\n",
    "        return pd.merge_asof(\n",
    "            group.sort_values('start'),\n",
    "            stay_labs,\n",
    "            left_on='start',\n",
    "            right_on='hours_since_adm',\n",
    "            direction='backward'\n",
    "        )\n",
    "    \n",
    "    cox_df = cox_df.groupby(\"stay_id\", group_keys=False).apply(merge_for_group)\n",
    "    cox_df = cox_df.reset_index(drop=True)  # Reset index without adding columns\n",
    "    \n",
    "    # Rename the merged column\n",
    "    cox_df = cox_df.rename(columns={lab_col: f'lab_{lab_col}'})\n",
    "    # Drop the hours_since_adm column added\n",
    "    if 'hours_since_adm' in cox_df.columns:\n",
    "        cox_df = cox_df.drop(columns=['hours_since_adm'])\n",
    "\n",
    "# Save\n",
    "cox_df.to_csv(output_path, index=False)\n",
    "print(f\"Saved updated cox_timevarying to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
